{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ1Go22Yi6qr"
      },
      "source": [
        "# 1. Data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvOfmVrNi6qz"
      },
      "source": [
        "### 1.1 Get the list of master's degree courses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxUQZX4li6q3"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import glob\n",
        "from nltk.stem import *\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from functools import reduce\n",
        "import heapq\n",
        "import re\n",
        "from forex_python.converter import CurrencyRates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMA45YNli6q4",
        "outputId": "2bf96ddd-1b2b-463e-8fc5-fc4f4fc94d52"
      },
      "outputs": [],
      "source": [
        "from defs import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqM3DXWOi6q6"
      },
      "source": [
        "Via the HTTP GET request we retrieve the content of the url of our interest, in our case the page that contains all the masters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMEOW5r5i6q7"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.findamasters.com/masters-degrees/msc-degrees/'\n",
        "result = requests.get(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjm57Szfi6q8"
      },
      "source": [
        "To extract all the links of the master's degree of the first 400 pages we used a function, which is located in the *defs.py* file; then we store all the links in the file *masters_urls.txt*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq_6zRtri6q9"
      },
      "outputs": [],
      "source": [
        "# to extract all the masters we have to do a for loop for the first 400 pages:\n",
        "\n",
        "num_pages = 400\n",
        "pref = 'https://www.findamasters.com'\n",
        "test_lst_all = []\n",
        "\n",
        "for i in range(1, num_pages + 1):\n",
        "    test_lst = extract_masters(pref + '/masters-degrees/msc-degrees/?PG=' + str(i))\n",
        "    test_lst_all.extend(test_lst)\n",
        "# creating the txt file of the fisrt 400 pages of ms\n",
        "with open('masters_urls.txt', 'w') as f:\n",
        "    for item in test_lst_all:\n",
        "        f.write(item[0] + '\\n')\n",
        "# file created"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LKS0mnAi6q-"
      },
      "source": [
        "### 1.2 Crawl master's degree pages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YFvtw7bi6q_"
      },
      "source": [
        "We are going to save each HTML page of each course in a different folder, one folder for each page it is in; so we'll obtain 400 folders, each of them will contain 15 HTML files. The urls are taken from the *masters_urls.txt* previusly created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFDd1GAxi6q_"
      },
      "outputs": [],
      "source": [
        "# settings for the User-Agent to simulate a browser\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'}\n",
        "folder_name = \"html_pages\" # create the folder that will contain the html pages\n",
        "html_name_url = {}\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "\n",
        "for i in range(1, 401):\n",
        "    # create a folder for each page, from 1 to 400\n",
        "    name = 'HTML page ' + str(i)\n",
        "    path_folder = os.path.join(folder_name, name)\n",
        "    if not os.path.exists(path_folder):\n",
        "        os.makedirs(path_folder)\n",
        "\n",
        "# open the file containing the urls\n",
        "with open('masters_urls.txt', 'r') as file:\n",
        "    for index, url in enumerate(file):\n",
        "        url = url.strip()\n",
        "        page = (index // 15 ) + 1\n",
        "        try:\n",
        "            # the complete url\n",
        "            full_url = \"https://www.findamasters.com\" + url.strip()\n",
        "\n",
        "            # add a delay of 1 to 5 seconds between the requests\n",
        "            time.sleep(1 + random.uniform(0, 4))\n",
        "            # request to obtain the content of the url\n",
        "            response = requests.get(full_url, headers=headers)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                # Parsing dell'HTML con BeautifulSoup\n",
        "                soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "                # save the html of the course in a separate file in the folder of the page it belongs to\n",
        "                file_path = os.path.join(f\"{folder_name}\\HTML page {page}\", f\"course {index+1}.html\")\n",
        "                with open(file_path, \"w\", encoding=\"utf-8\") as html_file:\n",
        "                    html_file.write(str(soup))\n",
        "                html_name_url[file_path] = full_url\n",
        "            else:\n",
        "                print(f\"Errore nel recuperare la pagina del corso: {full_url}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Errore durante il recupero e salvataggio della pagina {full_url}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcW8RrVUi6rA"
      },
      "source": [
        "### 1.3 Parse download pages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8uGfIeUi6rB"
      },
      "source": [
        "Through the *extcat_msc_page* function (located in the *defs.py*) we parse all the HTML we retrieved before and collect all the information for each master."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kdk-pViFi6rB"
      },
      "outputs": [],
      "source": [
        "#Directory where there are the HTML repositories\n",
        "html_folder = \"\\html-pages\"\n",
        "my_path = \"D:\\Primo Semestre\\ADM\\HW3\"\n",
        "#List to contain all the information\n",
        "all_master_info = []\n",
        "\n",
        "all_url = []\n",
        "\n",
        "#Iterating whitin the repositories HTML of every page\n",
        "for page_folder in os.listdir(my_path + html_folder):\n",
        "    page_path = os.path.join(html_folder, page_folder)\n",
        "    file_absolute_path = os.path.join(my_path + page_path)\n",
        "\n",
        "    if os.path.isdir(file_absolute_path):\n",
        "        #Iterating in the files HTML of every repository\n",
        "        for file in os.listdir(file_absolute_path):\n",
        "            if file.endswith(\".html\"):\n",
        "                file_path = os.path.join(file_absolute_path, file)\n",
        "                print('FILE PATH: ', file_path)\n",
        "                #Applying the function extract_msc_page to every file HTML\n",
        "                master_info = extract_msc_page(file_path)\n",
        "                all_master_info.extend(master_info)\n",
        "\n",
        "print(all_master_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R-xmzzwi6rC"
      },
      "source": [
        "Then we're storing those information in a tsv file, one for each master. All the files are stored in a folder called 'Tsv files'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4tk0PhFi6rC"
      },
      "outputs": [],
      "source": [
        "# creating the tsv file for each master\n",
        "\n",
        "folder_name = \"Tsv files\"\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "folder_path = \"D:\\Primo Semestre\\ADM\\HW3\\Tsv files\"\n",
        "\n",
        "for i in range(0,len(all_master_info)):\n",
        "    output_file = f\"{folder_path}\\course_{i+1}.tsv\"\n",
        "    with open(output_file, 'w', encoding='utf-8') as tsvfile:\n",
        "    # Extract field names from the dictionaries in 'all_master_info'\n",
        "        fieldnames = all_master_info[i].keys()\n",
        "        tsvfile.write('\\t'.join(fieldnames) + '\\n')                  # write the header\n",
        "        row = '\\t'.join(str(all_master_info[i].get(field, '')) for field in fieldnames)\n",
        "        tsvfile.write(row + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-je0c8ri6rD"
      },
      "source": [
        "We can now create our dataframe, reading the data on all the tsv files we just created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPJv7zKli6rE"
      },
      "outputs": [],
      "source": [
        "data_frames = []\n",
        "file_name_list = glob.glob(\"Tsv files\\course_*.tsv\")    # take all the course_i.tsv files\n",
        "for file in file_name_list:\n",
        "    dataset_tsv = pd.read_csv(file, sep='\\t', header=0)      # create the data frame from the tsv file\n",
        "    data_frames.append(dataset_tsv)\n",
        "# Concatenate all DataFrames in the list into a single DataFrame\n",
        "dataset = pd.concat(data_frames, ignore_index=True)     # creating the whole dataframe from each tsv file\n",
        "\n",
        "dataset = dataset[dataset.description != ''] # do not ocnsider all the rows that have an empty description\n",
        "\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHbT-9wYi6rE"
      },
      "source": [
        "**da eliminare poi questo**  perchè per semplicitò apriamo il dataset da un file json, ma in realtà dovremmo aprirlo dai file tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FT5Kh0_ji6rF"
      },
      "outputs": [],
      "source": [
        "# opening the json file for the dataset (but it will be the tsv file)\n",
        "path = r\"university_dataset.json\"\n",
        "dataset= pd.read_json(path)\n",
        "dataset.dropna(subset=['description'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpRHBfiJi6rF"
      },
      "source": [
        "# 2. Search Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCVJ4Qo2i6rF"
      },
      "source": [
        "### 2.0 Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJs_UoQni6rG"
      },
      "source": [
        "2.0.0 Preprocessing the text\\\n",
        "We created 3 functions, that are present in the *defs.py*, to perform the stemming, remove the stopwords and punctuation from the *description* field of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90vvjpgSi6rG"
      },
      "outputs": [],
      "source": [
        "# removing rows where the description is empty\n",
        "dataset = dataset[dataset['description'].notna()]\n",
        "dataset = dataset[dataset['fees'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgLaLMZ4i6rG"
      },
      "outputs": [],
      "source": [
        "# 1. stemming\n",
        "dataset['descr_stem'] = dataset['description'].apply(stem_description)\n",
        "\n",
        "# 2. removing stopwords\n",
        "dataset['description_clean'] = dataset['descr_stem'].apply(lambda row: remove_stopwords(row))\n",
        "\n",
        "# 3. removing punctuation\n",
        "dataset['description_clean'] = dataset['description_clean'].apply(lambda row: remove_punctuation(row))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGK0estji6rH"
      },
      "source": [
        "2.0.1 preprocess the *fees* column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBOxsK-ei6rH"
      },
      "source": [
        "get value of cost, from fees colum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KVzxpUHi6rH"
      },
      "outputs": [],
      "source": [
        "university_cost = {}\n",
        "pattern = r'\\b(?:\\$\\s?|€|£|¥|₹|\\b(?:USD|EUR|GBP|JPY|INR)\\b|\\b(?:dollari|euro|sterline|yen|rupie)\\b|\\b(?:dollar|euro|pound|yen|rupee)\\b)\\s?([\\d,]+(?:\\.\\d{1,2})?)\\b'\n",
        "for index, i in enumerate(dataset['fees']):\n",
        "    if isinstance(i, str):\n",
        "        corrispondenze = re.finditer(pattern, i, flags=re.IGNORECASE)\n",
        "        valori_monetari = [(match.group(1), match.group(0)) for match in corrispondenze]\n",
        "\n",
        "        # Trova la valuta e il costo con il valore monetario più alto\n",
        "        if valori_monetari:\n",
        "            costo, valuta = max(valori_monetari, key=lambda x: float(x[0].replace(',', '')))\n",
        "\n",
        "            # Estrai solo il simbolo della valuta\n",
        "            simbolo_valuta_match = re.search(r'(£|\\$|€|¥|₹|\\b(?:USD|EUR|GBP|JPY|INR)\\b|\\b(?:dollari|euro|sterline|yen|rupie)\\b|\\b(?:dollar|euro|pound|yen|rupee)\\b)', valuta)\n",
        "\n",
        "            # Verifica se c'è una corrispondenza prima di chiamare group\n",
        "            simbolo_valuta = simbolo_valuta_match.group(1) if simbolo_valuta_match else None\n",
        "\n",
        "            university_cost[index] = {'costo': costo, 'valuta': simbolo_valuta}\n",
        "        else:\n",
        "            university_cost[index] = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HFgTAw2i6rI"
      },
      "outputs": [],
      "source": [
        "dataset['fees'] = university_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzsCMzeQi6rI"
      },
      "source": [
        "We're using the functions defined in the *defs* file to handle the fees curency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc18t_v6i6rJ"
      },
      "outputs": [],
      "source": [
        "# apply the function to the 'fees' column\n",
        "dataset['fees'] = dataset['fees'].apply(convert_and_replace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_6yV6IOi6rJ"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.rename(columns={'fees': 'fees (EUR)'})\n",
        "#dataset = dataset[dataset['fees (EUR)'].notna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4m-rvCJi6rJ"
      },
      "source": [
        "### 2.1 Conjuctive query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x77HYcmyi6rK"
      },
      "source": [
        "2.1.1 Create the index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdWMh1wEi6rK"
      },
      "source": [
        "We created the vocabulary assigning an unique ID to each word encoutered in the description field of the dataset, then created a csv file out of it, to store the information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CSB7DY9i6rK"
      },
      "outputs": [],
      "source": [
        "# creating the vocabulary\n",
        "vocabulary = Counter(reduce(lambda x,y : x+y, dataset.description_clean)).keys()\n",
        "\n",
        "# assign an unique ID to each word of the vocabulary using a pandas dataframe\n",
        "terms = pd.DataFrame(data=list(vocabulary), columns=['term'])\n",
        "\n",
        "terms\n",
        "# creating a csv file for the vocabulary with index of each term\n",
        "terms.to_csv('vocabulary.csv', index_label='term_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0hUXHxji6rL"
      },
      "source": [
        "Now we can create the inverted index as a new column of the dataframe *terms* and store it in a txt file, called *Inverted Index.txt*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOS6AAwai6rL"
      },
      "outputs": [],
      "source": [
        "terms = pd.read_csv('vocabulary.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g02_bTU6i6rU",
        "outputId": "22aca81e-fe0c-4ba3-9d42-61b6c07688c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term_id</th>\n",
              "      <th>term</th>\n",
              "      <th>reverse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3d</td>\n",
              "      <td>[0, 444, 508, 593, 594, 890, 1838, 2437, 2833,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>visualis</td>\n",
              "      <td>[0, 68, 70, 399, 741, 1283, 1299, 1430, 1431, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>anim</td>\n",
              "      <td>[0, 9, 20, 241, 681, 969, 1028, 1029, 1030, 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>play</td>\n",
              "      <td>[0, 16, 33, 70, 80, 182, 194, 273, 305, 318, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>role</td>\n",
              "      <td>[0, 35, 61, 70, 74, 80, 138, 161, 163, 172, 17...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   term_id      term                                            reverse\n",
              "0        0        3d  [0, 444, 508, 593, 594, 890, 1838, 2437, 2833,...\n",
              "1        1  visualis  [0, 68, 70, 399, 741, 1283, 1299, 1430, 1431, ...\n",
              "2        2      anim  [0, 9, 20, 241, 681, 969, 1028, 1029, 1030, 10...\n",
              "3        3      play  [0, 16, 33, 70, 80, 182, 194, 273, 305, 318, 3...\n",
              "4        4      role  [0, 35, 61, 70, 74, 80, 138, 161, 163, 172, 17..."
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "terms['reverse'] = terms.term.apply(lambda item: list(dataset.loc[dataset.description_clean.apply(lambda row: item in row)].index))\n",
        "terms.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szAMBLXyi6rV"
      },
      "source": [
        "We now transform the inverted index in a dictionary in this form\\\n",
        "<code> {\n",
        "term_id_1:[document_1, document_2, document_4],\n",
        "term_id_2:[document_1, document_3, document_5, document_6],\n",
        "    ...}\n",
        "</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHb6dCR1i6rV",
        "outputId": "5773746b-ca95-4bf2-92e9-530de1425e4f"
      },
      "outputs": [],
      "source": [
        "InvertedIndex = terms['reverse'].to_dict()\n",
        "\n",
        "# store the inverted index in a txt file\n",
        "with open('Inverted Index.txt', 'w') as file:\n",
        "\n",
        "    for key, value in InvertedIndex.items():\n",
        "        file.write(f'{key}: {value}\\n')\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxiKUPTCi6rW"
      },
      "outputs": [],
      "source": [
        "# read back the inverted index from the file.\n",
        "\n",
        "file = open(\"Inverted Index.txt\", \"r\")\n",
        "\n",
        "inv_indx = dict()\n",
        "txt = file.read().split(\"\\n\")\n",
        "\n",
        "for i in range(len(txt)-1):\n",
        "    line = txt[i].replace(\":\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").split(\" \")\n",
        "    inv_indx[int(line[0])] = []\n",
        "    for j in range(1, len(line)):\n",
        "            inv_indx[int(line[0])].append(int(line[j]))\n",
        "\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WADVCFJQi6rW"
      },
      "source": [
        "2.1.2 Execute the query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgJUqSQFi6rX"
      },
      "source": [
        "We created a function called *query_preprocess* that preprocesses the query just like we did in the preprocess of the description field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM3c9gtti6rX",
        "outputId": "98df6d6a-4eb0-46ec-bac7-115fbb18901b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting query: advanced knoledge\n",
            "preprocessed query: ['advanc', 'knoledg']\n"
          ]
        }
      ],
      "source": [
        "#query = str(input())\n",
        "starting_query = 'advanced knoledge'\n",
        "print('starting query:',starting_query)\n",
        "# formatting the query\n",
        "query = query_preprocess(starting_query)\n",
        "print('preprocessed query:',query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYF9Ssv7i6rX"
      },
      "source": [
        "What we're going to do now to implement our Search Engine is:\n",
        "- Find all the words of the query in the vocabulary and exctract each *term_id* of each word of the query.\n",
        "- Find all the documents related to each *term_id* in the Inverted Index.\n",
        "- Do the intersection of the lists of documents found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuTds4Ivi6rY",
        "outputId": "ac01aec0-4133-4eae-aad5-d87af3ad2790"
      },
      "outputs": [],
      "source": [
        "vocabulary = pd.read_csv('vocabulary.csv') # read the vocabulary file into a dataframe\n",
        "vocabulary = pd.DataFrame(vocabulary)\n",
        "\n",
        "file = open(\"Inverted Index.txt\", \"r\") # read the inverted index from the file.\n",
        "\n",
        "inv_indx = dict()\n",
        "txt = file.read().split(\"\\n\")\n",
        "\n",
        "for i in range(len(txt)-1):\n",
        "    line = txt[i].replace(\":\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").split(\" \")\n",
        "    inv_indx[int(line[0])] = []\n",
        "    for j in range(1, len(line)):\n",
        "            inv_indx[int(line[0])].append(int(line[j]))\n",
        "file.close()\n",
        "\n",
        "# find the words of the query in the vocabulary\n",
        "for w in query:\n",
        "    term_ids = [vocabulary[vocabulary['term'] == w]['term_id'].values for w in query if w in vocabulary.term.values]\n",
        "\n",
        "term_ids = [term_ids[x][0] for x in range(len(term_ids))] # exctract only the integers of the ids\n",
        "\n",
        "# find the documents\n",
        "docs = [inv_indx[i] for i in term_ids]\n",
        "\n",
        "# intersecting the two sets of documents we found out contain all the word of the query\n",
        "intersection = list(set(docs[0]).intersection(*docs[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EaPVayFi6rZ"
      },
      "source": [
        "Now we can show the results of the query after it passed into the search engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0orc1N6ci6rZ",
        "outputId": "0dcd9d18-ba6e-4869-ae20-15b740116820"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>courseName</th>\n",
              "      <th>universityName</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Accounting and Finance - MSc</td>\n",
              "      <td>University of Leeds</td>\n",
              "      <td>Businesses and governments rely on sound finan...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Accounting, Accountability &amp; Financial Managem...</td>\n",
              "      <td>King’s College London</td>\n",
              "      <td>Our Accounting, Accountability &amp; Financial Man...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Addictions MSc</td>\n",
              "      <td>King’s College London</td>\n",
              "      <td>Join us for an online session for prospective ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Advanced Chemical Engineering - MSc</td>\n",
              "      <td>University of Leeds</td>\n",
              "      <td>The Advanced Chemical Engineering MSc at Leeds...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Advanced Master in Financial Markets</td>\n",
              "      <td>Solvay Brussels School</td>\n",
              "      <td>Programme overviewThe Advanced Master in Finan...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4019</th>\n",
              "      <td>Glaciology MSc by Research</td>\n",
              "      <td>Swansea University</td>\n",
              "      <td>The MSc by Research in Glaciology allows you t...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4022</th>\n",
              "      <td>Global Ageing MSc (Online)</td>\n",
              "      <td>University of Stirling</td>\n",
              "      <td>According to the WHO, between 2015 and 2050 th...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4023</th>\n",
              "      <td>Global Biodiversity Conservation - MSc</td>\n",
              "      <td>University of Sussex</td>\n",
              "      <td>This MSc will give you advanced knowledge and ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4069</th>\n",
              "      <td>Global Health MSc</td>\n",
              "      <td>St George’s, University of London</td>\n",
              "      <td>Significant socioeconomic and environmental ch...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4074</th>\n",
              "      <td>Global Health, Social Justice and Public Polic...</td>\n",
              "      <td>King’s College London</td>\n",
              "      <td>Our Global Health, Social Justice and Public P...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1041 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             courseName  \\\n",
              "1                          Accounting and Finance - MSc   \n",
              "2     Accounting, Accountability & Financial Managem...   \n",
              "4                                        Addictions MSc   \n",
              "5                   Advanced Chemical Engineering - MSc   \n",
              "6                  Advanced Master in Financial Markets   \n",
              "...                                                 ...   \n",
              "4019                         Glaciology MSc by Research   \n",
              "4022                         Global Ageing MSc (Online)   \n",
              "4023             Global Biodiversity Conservation - MSc   \n",
              "4069                                  Global Health MSc   \n",
              "4074  Global Health, Social Justice and Public Polic...   \n",
              "\n",
              "                         universityName  \\\n",
              "1                   University of Leeds   \n",
              "2                 King’s College London   \n",
              "4                 King’s College London   \n",
              "5                   University of Leeds   \n",
              "6                Solvay Brussels School   \n",
              "...                                 ...   \n",
              "4019                 Swansea University   \n",
              "4022             University of Stirling   \n",
              "4023               University of Sussex   \n",
              "4069  St George’s, University of London   \n",
              "4074              King’s College London   \n",
              "\n",
              "                                            description  \\\n",
              "1     Businesses and governments rely on sound finan...   \n",
              "2     Our Accounting, Accountability & Financial Man...   \n",
              "4     Join us for an online session for prospective ...   \n",
              "5     The Advanced Chemical Engineering MSc at Leeds...   \n",
              "6     Programme overviewThe Advanced Master in Finan...   \n",
              "...                                                 ...   \n",
              "4019  The MSc by Research in Glaciology allows you t...   \n",
              "4022  According to the WHO, between 2015 and 2050 th...   \n",
              "4023  This MSc will give you advanced knowledge and ...   \n",
              "4069  Significant socioeconomic and environmental ch...   \n",
              "4074  Our Global Health, Social Justice and Public P...   \n",
              "\n",
              "                                                    url  \n",
              "1     https://www.findamasters.com/masters-degrees/c...  \n",
              "2     https://www.findamasters.com/masters-degrees/c...  \n",
              "4     https://www.findamasters.com/masters-degrees/c...  \n",
              "5     https://www.findamasters.com/masters-degrees/c...  \n",
              "6     https://www.findamasters.com/masters-degrees/c...  \n",
              "...                                                 ...  \n",
              "4019  https://www.findamasters.com/masters-degrees/c...  \n",
              "4022  https://www.findamasters.com/masters-degrees/c...  \n",
              "4023  https://www.findamasters.com/masters-degrees/c...  \n",
              "4069  https://www.findamasters.com/masters-degrees/c...  \n",
              "4074  https://www.findamasters.com/masters-degrees/c...  \n",
              "\n",
              "[1041 rows x 4 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "information_needed = ['courseName','universityName','description', 'url']\n",
        "dataset.loc[intersection,information_needed]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cigH3pX7i6rZ"
      },
      "source": [
        "## 2.2 Conjunctive query & Ranking score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgB4skUAi6ra"
      },
      "source": [
        "2.2.1 Inverted Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpfH_3AGi6ra"
      },
      "source": [
        "We are now going to implement a ranking system, computing the *TF-Idataset* for each word in each document, and then calculating the *cosine similarity* between the query vector and each one of the vectors corresponding to the documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f33dqCm4i6rb"
      },
      "outputs": [],
      "source": [
        "# tf-idataset\n",
        "# use the library scikit-learn: tfidataset implementation VECTORIZED\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iAo2zdci6rb",
        "outputId": "523b8ff2-ab98-4292-cf3f-5bd355de8ccb"
      },
      "outputs": [],
      "source": [
        "#Convert a collection of raw documents to a matrix of TF-Idataset features\n",
        "\n",
        "tfidataset = TfidfVectorizer(input='content', lowercase=False, tokenizer=lambda text: text)\n",
        "results = tfidataset.fit_transform(dataset.description_clean) # fit data to train our model (but in our case is the same dataset)\n",
        "results_dense = results.todense() # results are sparse documents that i want to convert into a dense one\n",
        "\n",
        "# putting all into a dataframe where the index of the dataframe is each document id\n",
        "tfidataset_data = pd.DataFrame(results_dense.tolist(), index=dataset.index, columns=tfidataset.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC3kWKK_i6rc"
      },
      "source": [
        "Creating our second inverted index in the form:\\\n",
        "<code>{\n",
        "term_id_1:[(document1, tfIdataset_{term,document1}), (document2, tfIdataset_{term,document2}), (document4, tfIdataset_{term,document4}), ...],\n",
        "term_id_2:[(document1, tfIdataset_{term,document1}), (document3, tfIdataset_{term,document3}), (document5, tfIdataset_{term,document5}), (document6, tfIdataset_{term,document6}), ...],\n",
        "...}\n",
        "</code>\n",
        "And then storing it in a txt file called *Extented Inverted Index.txt*\\\n",
        "The functions we used are defined in the *defs.py* file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8aNgfkvi6rc"
      },
      "outputs": [],
      "source": [
        "create_second_inverted_index(inv_indx, vocabulary, tfidataset_data, feat='description')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BygFpXPyi6rd"
      },
      "outputs": [],
      "source": [
        "# read the inverted index from the file.\n",
        "ext_inv_indx = read_inverted_index('description')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7cBqUS4i6rd"
      },
      "source": [
        "2.2.2 Execute the query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK70WvEJi6re"
      },
      "source": [
        "We created the query vector, putting a 1 if the word corresponding to the position is present in the query, 0 if is not.\\\n",
        "The vector for each description is each row of the dataframe tfidataset, so no need to compute it for each document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYpKyyR0i6re"
      },
      "outputs": [],
      "source": [
        "query_vec = create_vector_query(query=query, vocabulary=vocabulary, tfidataset_data=tfidataset_data )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2vML3Gci6re"
      },
      "source": [
        "Now we need the cosine similarity function that we wrote in the *defs.py*, which simply exploits the definition of the cosine similaruty between two vectors that create the $\\phi$ angle:\n",
        "\n",
        "$cos(\\phi) = \\frac{\\vec{q} \\cdot \\vec{d}}{|{\\vec{q}}| \\cdot |{\\vec{d}}|}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgeqvM4Gi6rf"
      },
      "source": [
        "Instead of using a list to store the similarity scores, we can use a heap structure, to make the sorting more efficient from a computational point of view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mknSZk6li6rf"
      },
      "outputs": [],
      "source": [
        "heap = []\n",
        "scores_dictionary = {}\n",
        "\n",
        "# For every document\n",
        "for doc_index in range(tfidataset_data.shape[0]):\n",
        "    if doc_index in tfidataset_data.index:\n",
        "        doc_arr = tfidataset_data.loc[doc_index, :].values\n",
        "        # Compute the angle between the doc and the query vector\n",
        "        cos_sim = a_cosine_similarity(query_vec, doc_arr)\n",
        "\n",
        "        # Put the result in the dictionary\n",
        "        scores_dictionary[doc_index] = cos_sim\n",
        "        # Update the heap\n",
        "        heapq.heappush(heap, (cos_sim, doc_index))  # Store both score and document index in the heap\n",
        "    else:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjzXCnTVi6rg"
      },
      "source": [
        "2.2.2 Execute the query with k = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIUJKHXii6rg",
        "outputId": "75714d94-cdcf-4ea0-940b-a10569d98ab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0.20374239362170501, 5209), (0.0, 5976), (0.0, 5975), (0.0, 5974), (0.0, 5973), (0.0, 5972)]\n",
            "[5209, 5976, 5975, 5974, 5973, 5972]\n"
          ]
        }
      ],
      "source": [
        "k = 6\n",
        "top_k, top_doc_k = execute_query(k, heap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJvYk99Oi6rh"
      },
      "source": [
        "The results of the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YL7UcuAi6rh",
        "outputId": "343dc8f9-4d68-40fc-9f10-74201602d2fd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>courseName</th>\n",
              "      <th>universityName</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5209</th>\n",
              "      <td>Management (International Business) - MSc</td>\n",
              "      <td>University of Reading</td>\n",
              "      <td>On this Masters programme, you will examine th...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5976</th>\n",
              "      <td>Masters's in Digital Politics and Governance</td>\n",
              "      <td>European School of Political and Social Scienc...</td>\n",
              "      <td>Digitalisation is a critical issue in today’s ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5975</th>\n",
              "      <td>Masters Program in Climate Change, Agriculture...</td>\n",
              "      <td>University of Galway</td>\n",
              "      <td>The world’s climate is rapidly changing due to...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5974</th>\n",
              "      <td>Masters of Science in Business, Supply Chain A...</td>\n",
              "      <td>Oregon State University</td>\n",
              "      <td>Master of Science in Business (MSB)Our Master ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5973</th>\n",
              "      <td>Masters of Science in Business</td>\n",
              "      <td>Oregon State University</td>\n",
              "      <td>Our Master of Science in Business (MSB) will g...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5972</th>\n",
              "      <td>Master's of Front-end Development</td>\n",
              "      <td>Harbour.Space University</td>\n",
              "      <td>Front-end Development at Harbour.Space Univers...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             courseName  \\\n",
              "5209          Management (International Business) - MSc   \n",
              "5976       Masters's in Digital Politics and Governance   \n",
              "5975  Masters Program in Climate Change, Agriculture...   \n",
              "5974  Masters of Science in Business, Supply Chain A...   \n",
              "5973                     Masters of Science in Business   \n",
              "5972                  Master's of Front-end Development   \n",
              "\n",
              "                                         universityName  \\\n",
              "5209                              University of Reading   \n",
              "5976  European School of Political and Social Scienc...   \n",
              "5975                               University of Galway   \n",
              "5974                            Oregon State University   \n",
              "5973                            Oregon State University   \n",
              "5972                           Harbour.Space University   \n",
              "\n",
              "                                            description  \\\n",
              "5209  On this Masters programme, you will examine th...   \n",
              "5976  Digitalisation is a critical issue in today’s ...   \n",
              "5975  The world’s climate is rapidly changing due to...   \n",
              "5974  Master of Science in Business (MSB)Our Master ...   \n",
              "5973  Our Master of Science in Business (MSB) will g...   \n",
              "5972  Front-end Development at Harbour.Space Univers...   \n",
              "\n",
              "                                                    url  similarity  \n",
              "5209  https://www.findamasters.com/masters-degrees/c...       0.204  \n",
              "5976  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5975  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5974  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5973  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5972  https://www.findamasters.com/masters-degrees/c...       0.000  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# adding the column 'similarity score' to the dataset\n",
        "rinformation_needed = ['courseName','universityName','description', 'url']\n",
        "results = dataset.loc[top_doc_k , information_needed]\n",
        "results['similarity'] = [round(s[0],3) for s in top_k]\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT66yJqli6ri"
      },
      "source": [
        "# 3. Define a new score!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjpEXBRPi6ri"
      },
      "source": [
        "3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G_dEAZIi6ri",
        "outputId": "bdc7235c-422f-4c66-816c-4da67998450c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['univers']\n"
          ]
        }
      ],
      "source": [
        "query_for_new_score = str(input())\n",
        "# formatting the query\n",
        "query_for_new_score = query_preprocess(query_for_new_score)\n",
        "print(query_for_new_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL2AixHEi6rj",
        "outputId": "40e1dae0-6b2d-477a-8d1d-809aad76aeba"
      },
      "outputs": [],
      "source": [
        "vocabulary = pd.read_csv('vocabulary.csv') # read the vocabulary file into a dataframe\n",
        "vocabulary = pd.DataFrame(vocabulary)\n",
        "\n",
        "file = open(\"Inverted Index.txt\", \"r\") # read the inverted index from the file.\n",
        "\n",
        "inv_indx = dict()\n",
        "txt = file.read().split(\"\\n\")\n",
        "\n",
        "for i in range(len(txt)-1):\n",
        "    line = txt[i].replace(\":\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").split(\" \")\n",
        "    inv_indx[int(line[0])] = []\n",
        "    for j in range(1, len(line)):\n",
        "            inv_indx[int(line[0])].append(int(line[j]))\n",
        "file.close()\n",
        "\n",
        "# find the words of the query in the vocabulary\n",
        "for w in query_for_new_score:\n",
        "    term_ids = [vocabulary[vocabulary['term'] == w]['term_id'].values for w in query_for_new_score if w in vocabulary.term.values]\n",
        "\n",
        "term_ids = [term_ids[x][0] for x in range(len(term_ids))] # exctract only the integers of the ids\n",
        "\n",
        "# find the documents\n",
        "docs = [inv_indx[i] for i in term_ids]\n",
        "\n",
        "# intersecting the two sets of documents we found out contain all the word of the query\n",
        "intersection = list(set(docs[0]).intersection(*docs[1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkOqxhVqi6rj",
        "outputId": "6643f49b-cc6f-4c3c-f1eb-0a624f9d64bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>courseName</th>\n",
              "      <th>universityName</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2051</th>\n",
              "      <td>Clinical Pharmacy Practice (PgCert/PgDip/MSc)</td>\n",
              "      <td>Robert Gordon University</td>\n",
              "      <td>The online MSc Clinical Pharmacy Practice cour...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4099</th>\n",
              "      <td>Global MBA</td>\n",
              "      <td>London School of Business &amp; Finance</td>\n",
              "      <td>Global MBA OnlineWhen you study with London Sc...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4100</th>\n",
              "      <td>Global Media and Communications (LSE and Fudan...</td>\n",
              "      <td>London School of Economics and Political Science</td>\n",
              "      <td>Ask LSEThe unique MSc double degree in Global ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4101</th>\n",
              "      <td>Global Media and Communications (LSE and UCT) MSc</td>\n",
              "      <td>London School of Economics and Political Science</td>\n",
              "      <td>Ask LSEThis unique double degree allows studen...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4102</th>\n",
              "      <td>Global Media and Communications (LSE and USC) MSc</td>\n",
              "      <td>London School of Economics and Political Science</td>\n",
              "      <td>Ask LSEThis unique double degree enables you t...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2032</th>\n",
              "      <td>Clinical Nutrition MSc, PgDip or PgCert</td>\n",
              "      <td>Aberdeen University</td>\n",
              "      <td>Are you interested in improving health outcome...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034</th>\n",
              "      <td>Clinical Oncology (Full time) - MSc/PGDip</td>\n",
              "      <td>University of Birmingham</td>\n",
              "      <td>For health care professionals from diverse bac...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2035</th>\n",
              "      <td>Clinical Oncology (Part time) - MSc/PGDip</td>\n",
              "      <td>University of Birmingham</td>\n",
              "      <td>A programme for health care professionals from...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2043</th>\n",
              "      <td>Clinical Pharmacology MSc</td>\n",
              "      <td>Aberdeen University</td>\n",
              "      <td>The University of Aberdeen is highly regarded ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>Global Marine Resource Management MSc</td>\n",
              "      <td>University of Southampton</td>\n",
              "      <td>Explore Marine Resource Management at a global...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>562 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             courseName  \\\n",
              "2051      Clinical Pharmacy Practice (PgCert/PgDip/MSc)   \n",
              "4099                                         Global MBA   \n",
              "4100  Global Media and Communications (LSE and Fudan...   \n",
              "4101  Global Media and Communications (LSE and UCT) MSc   \n",
              "4102  Global Media and Communications (LSE and USC) MSc   \n",
              "...                                                 ...   \n",
              "2032            Clinical Nutrition MSc, PgDip or PgCert   \n",
              "2034          Clinical Oncology (Full time) - MSc/PGDip   \n",
              "2035          Clinical Oncology (Part time) - MSc/PGDip   \n",
              "2043                          Clinical Pharmacology MSc   \n",
              "4095              Global Marine Resource Management MSc   \n",
              "\n",
              "                                        universityName  \\\n",
              "2051                          Robert Gordon University   \n",
              "4099               London School of Business & Finance   \n",
              "4100  London School of Economics and Political Science   \n",
              "4101  London School of Economics and Political Science   \n",
              "4102  London School of Economics and Political Science   \n",
              "...                                                ...   \n",
              "2032                               Aberdeen University   \n",
              "2034                          University of Birmingham   \n",
              "2035                          University of Birmingham   \n",
              "2043                               Aberdeen University   \n",
              "4095                         University of Southampton   \n",
              "\n",
              "                                            description  \\\n",
              "2051  The online MSc Clinical Pharmacy Practice cour...   \n",
              "4099  Global MBA OnlineWhen you study with London Sc...   \n",
              "4100  Ask LSEThe unique MSc double degree in Global ...   \n",
              "4101  Ask LSEThis unique double degree allows studen...   \n",
              "4102  Ask LSEThis unique double degree enables you t...   \n",
              "...                                                 ...   \n",
              "2032  Are you interested in improving health outcome...   \n",
              "2034  For health care professionals from diverse bac...   \n",
              "2035  A programme for health care professionals from...   \n",
              "2043  The University of Aberdeen is highly regarded ...   \n",
              "4095  Explore Marine Resource Management at a global...   \n",
              "\n",
              "                                                    url  \n",
              "2051  https://www.findamasters.com/masters-degrees/c...  \n",
              "4099  https://www.findamasters.com/masters-degrees/c...  \n",
              "4100  https://www.findamasters.com/masters-degrees/c...  \n",
              "4101  https://www.findamasters.com/masters-degrees/c...  \n",
              "4102  https://www.findamasters.com/masters-degrees/c...  \n",
              "...                                                 ...  \n",
              "2032  https://www.findamasters.com/masters-degrees/c...  \n",
              "2034  https://www.findamasters.com/masters-degrees/c...  \n",
              "2035  https://www.findamasters.com/masters-degrees/c...  \n",
              "2043  https://www.findamasters.com/masters-degrees/c...  \n",
              "4095  https://www.findamasters.com/masters-degrees/c...  \n",
              "\n",
              "[562 rows x 4 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "information_needed = ['courseName','universityName','description', 'url']\n",
        "dataset.loc[intersection,information_needed]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kNRhYl7i6rk",
        "outputId": "32da00d7-1229-45e8-8949-f08720a94fe3"
      },
      "outputs": [],
      "source": [
        "#Convert a collection of raw documents to a matrix of TF-Idataset features\n",
        "tfidataset = TfidfVectorizer(input='content', lowercase=False, tokenizer=lambda text: text)\n",
        "results = tfidataset.fit_transform(dataset.description_clean) # fit data to train our model (but in our case is the same dataset)\n",
        "results_dense = results.todense() # results are sparse documents that i want to convert into a dense one\n",
        "\n",
        "# putting all into a dataframe where the index of the dataframe is each document id\n",
        "tfidataset_data = pd.DataFrame(results_dense.tolist(), index=dataset.index, columns=tfidataset.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmopII9ii6rl"
      },
      "outputs": [],
      "source": [
        "create_second_inverted_index(inv_indx, vocabulary, tfidataset_data, feat='description')\n",
        "second_query_vec = create_vector_query(query_for_new_score, vocabulary, tfidataset_data)\n",
        "heap_second_query = []\n",
        "scores_dictionary_second_query = {}\n",
        "#compute_cosine_similarity(heap_second_query, scores_dictionary_second_query)\n",
        "\n",
        "\n",
        "# For every document\n",
        "for doc_index in range(tfidataset_data.shape[0]):\n",
        "    if doc_index in tfidataset_data.index:\n",
        "        doc_arr = tfidataset_data.loc[doc_index, :].values\n",
        "        # Compute the angle between the doc and the query vector\n",
        "        cos_sim = a_cosine_similarity(second_query_vec, doc_arr)\n",
        "\n",
        "        # Put the result in the dictionary\n",
        "        scores_dictionary_second_query[doc_index] = cos_sim\n",
        "        # Update the heap\n",
        "        heapq.heappush(heap_second_query, (cos_sim, doc_index))  # Store both score and document index in the heap\n",
        "    else:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX75Vp4-i6rm",
        "outputId": "c0c86163-71ea-4089-e620-2505c773cfd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0.20647963214052836, 4462), (0.0, 5976), (0.0, 5975), (0.0, 5974), (0.0, 5973), (0.0, 5972), (0.0, 5971), (0.0, 5970), (0.0, 5969), (0.0, 5968), (0.0, 5967), (0.0, 5966), (0.0, 5965), (0.0, 5964), (0.0, 5963), (0.0, 5962), (0.0, 5961), (0.0, 5960), (0.0, 5959), (0.0, 5958)]\n",
            "[4462, 5976, 5975, 5974, 5973, 5972, 5971, 5970, 5969, 5968, 5967, 5966, 5965, 5964, 5963, 5962, 5961, 5960, 5959, 5958]\n"
          ]
        }
      ],
      "source": [
        "k = 20\n",
        "top_k, top_doc_k = execute_query(k, heap_second_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOWZlLmyi6rm",
        "outputId": "33c79a23-7866-4ec5-d03c-ea401c0da0c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>courseName</th>\n",
              "      <th>universityName</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4462</th>\n",
              "      <td>Improvement Science - MSc</td>\n",
              "      <td>University of West London</td>\n",
              "      <td>Do you work in the health sector? Is there an ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5976</th>\n",
              "      <td>Masters's in Digital Politics and Governance</td>\n",
              "      <td>European School of Political and Social Scienc...</td>\n",
              "      <td>Digitalisation is a critical issue in today’s ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5975</th>\n",
              "      <td>Masters Program in Climate Change, Agriculture...</td>\n",
              "      <td>University of Galway</td>\n",
              "      <td>The world’s climate is rapidly changing due to...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5974</th>\n",
              "      <td>Masters of Science in Business, Supply Chain A...</td>\n",
              "      <td>Oregon State University</td>\n",
              "      <td>Master of Science in Business (MSB)Our Master ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5973</th>\n",
              "      <td>Masters of Science in Business</td>\n",
              "      <td>Oregon State University</td>\n",
              "      <td>Our Master of Science in Business (MSB) will g...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5972</th>\n",
              "      <td>Master's of Front-end Development</td>\n",
              "      <td>Harbour.Space University</td>\n",
              "      <td>Front-end Development at Harbour.Space Univers...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>Master's of Financial Technology (Fintech)</td>\n",
              "      <td>Harbour.Space University</td>\n",
              "      <td>Harbour.Space's FinTech Master programme is de...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>Masters Of Finance (International Finance)</td>\n",
              "      <td>Zhejiang Gongshan University</td>\n",
              "      <td>Master’s in Finance (International Finance) at...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5969</th>\n",
              "      <td>Masters of Finance</td>\n",
              "      <td>University of Hong Kong</td>\n",
              "      <td>The HKU Business School Master of Finance (MFi...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5968</th>\n",
              "      <td>Master's of Data Science</td>\n",
              "      <td>Harbour.Space University</td>\n",
              "      <td>Harbour.Space’s Master of Data Science prepare...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5967</th>\n",
              "      <td>Master's of Cyber Security</td>\n",
              "      <td>Harbour.Space University</td>\n",
              "      <td>Harbour.Space’s Master's of Cyber Security off...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5966</th>\n",
              "      <td>Master's of Computer Science</td>\n",
              "      <td>Harbour.Space University</td>\n",
              "      <td>Harbour.Space’s Master's of Computer Science i...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5965</th>\n",
              "      <td>Master's in Sustainable and Autonomous Systems</td>\n",
              "      <td>University of Oulu</td>\n",
              "      <td>Degree title: Master of Science (Technology)St...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5964</th>\n",
              "      <td>Master's in Strategy and Management</td>\n",
              "      <td>NHH Norwegian School of Economics</td>\n",
              "      <td>The study of strategy is fundamentally about u...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5963</th>\n",
              "      <td>Masters in Monetary and Financial Economics</td>\n",
              "      <td>University of Lisbon</td>\n",
              "      <td>OVERVIEWThe Master's in Monetary and Financial...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5962</th>\n",
              "      <td>Masters in Mathematical Finance</td>\n",
              "      <td>University of Lisbon</td>\n",
              "      <td>OBJECTIVESThe Masters in Mathematical Finance ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5961</th>\n",
              "      <td>Master's in Marketing and Brand Management</td>\n",
              "      <td>NHH Norwegian School of Economics</td>\n",
              "      <td>Innovating, building and managing strong brand...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5960</th>\n",
              "      <td>Masters in Marine Science &amp; Climate Change</td>\n",
              "      <td>University of Gibraltar</td>\n",
              "      <td>Designed and delivered by expert academics and...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5959</th>\n",
              "      <td>Masters in Management (MiM)</td>\n",
              "      <td>University of Lisbon</td>\n",
              "      <td>Objetives:Framed within the United Nation’s 17...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5958</th>\n",
              "      <td>Master's in Management</td>\n",
              "      <td>London School of Economics and Political Science</td>\n",
              "      <td>Ask LSEThe Master’s in Management is an intens...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             courseName  \\\n",
              "4462                          Improvement Science - MSc   \n",
              "5976       Masters's in Digital Politics and Governance   \n",
              "5975  Masters Program in Climate Change, Agriculture...   \n",
              "5974  Masters of Science in Business, Supply Chain A...   \n",
              "5973                     Masters of Science in Business   \n",
              "5972                  Master's of Front-end Development   \n",
              "5971         Master's of Financial Technology (Fintech)   \n",
              "5970         Masters Of Finance (International Finance)   \n",
              "5969                                 Masters of Finance   \n",
              "5968                           Master's of Data Science   \n",
              "5967                         Master's of Cyber Security   \n",
              "5966                       Master's of Computer Science   \n",
              "5965     Master's in Sustainable and Autonomous Systems   \n",
              "5964                Master's in Strategy and Management   \n",
              "5963        Masters in Monetary and Financial Economics   \n",
              "5962                    Masters in Mathematical Finance   \n",
              "5961         Master's in Marketing and Brand Management   \n",
              "5960         Masters in Marine Science & Climate Change   \n",
              "5959                        Masters in Management (MiM)   \n",
              "5958                             Master's in Management   \n",
              "\n",
              "                                         universityName  \\\n",
              "4462                          University of West London   \n",
              "5976  European School of Political and Social Scienc...   \n",
              "5975                               University of Galway   \n",
              "5974                            Oregon State University   \n",
              "5973                            Oregon State University   \n",
              "5972                           Harbour.Space University   \n",
              "5971                           Harbour.Space University   \n",
              "5970                       Zhejiang Gongshan University   \n",
              "5969                            University of Hong Kong   \n",
              "5968                           Harbour.Space University   \n",
              "5967                           Harbour.Space University   \n",
              "5966                           Harbour.Space University   \n",
              "5965                                 University of Oulu   \n",
              "5964                  NHH Norwegian School of Economics   \n",
              "5963                               University of Lisbon   \n",
              "5962                               University of Lisbon   \n",
              "5961                  NHH Norwegian School of Economics   \n",
              "5960                            University of Gibraltar   \n",
              "5959                               University of Lisbon   \n",
              "5958   London School of Economics and Political Science   \n",
              "\n",
              "                                            description  \\\n",
              "4462  Do you work in the health sector? Is there an ...   \n",
              "5976  Digitalisation is a critical issue in today’s ...   \n",
              "5975  The world’s climate is rapidly changing due to...   \n",
              "5974  Master of Science in Business (MSB)Our Master ...   \n",
              "5973  Our Master of Science in Business (MSB) will g...   \n",
              "5972  Front-end Development at Harbour.Space Univers...   \n",
              "5971  Harbour.Space's FinTech Master programme is de...   \n",
              "5970  Master’s in Finance (International Finance) at...   \n",
              "5969  The HKU Business School Master of Finance (MFi...   \n",
              "5968  Harbour.Space’s Master of Data Science prepare...   \n",
              "5967  Harbour.Space’s Master's of Cyber Security off...   \n",
              "5966  Harbour.Space’s Master's of Computer Science i...   \n",
              "5965  Degree title: Master of Science (Technology)St...   \n",
              "5964  The study of strategy is fundamentally about u...   \n",
              "5963  OVERVIEWThe Master's in Monetary and Financial...   \n",
              "5962  OBJECTIVESThe Masters in Mathematical Finance ...   \n",
              "5961  Innovating, building and managing strong brand...   \n",
              "5960  Designed and delivered by expert academics and...   \n",
              "5959  Objetives:Framed within the United Nation’s 17...   \n",
              "5958  Ask LSEThe Master’s in Management is an intens...   \n",
              "\n",
              "                                                    url  similarity  \n",
              "4462  https://www.findamasters.com/masters-degrees/c...       0.206  \n",
              "5976  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5975  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5974  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5973  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5972  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5971  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5970  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5969  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5968  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5967  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5966  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5965  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5964  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5963  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5962  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5961  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5960  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5959  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "5958  https://www.findamasters.com/masters-degrees/c...       0.000  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# adding the column 'similarity score' to the dataset\n",
        "rinformation_needed = ['courseName','universityName','description', 'url']\n",
        "results = dataset.loc[top_doc_k , information_needed]\n",
        "results['similarity'] = [round(s[0],3) for s in top_k]\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoODyMepi6rn"
      },
      "source": [
        "# 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odAP-ZE-i6rn"
      },
      "source": [
        "Heap Data Structure Operations:\n",
        "\n",
        "1. **Heapify:**\n",
        "   Heapify is the process of transforming an array into a heap. This involves arranging the elements in a way that satisfies the heap property.\n",
        "\n",
        "2. **Insertion:**\n",
        "   The insertion operation involves adding an element to an existing heap. The time complexity of this operation is O(log N), where N is the number of elements in the heap. This is because the element may need to be moved up the heap to maintain the heap property.\n",
        "\n",
        "3. **Deletion:**\n",
        "   Deletion in a heap typically refers to removing the top element (root) of the heap or the element with the highest priority. After removal, the heap is reorganized to maintain the heap property. The time complexity of this operation is O(log N) because the reorganization involves adjusting the heap structure.\n",
        "\n",
        "4. **Peek:**\n",
        "   Peek operation is used to inspect the top element of the heap without removing it. It allows checking or finding the element with the highest priority. The time complexity is constant, O(1).\n",
        "\n",
        "Types of Heap Data Structures:\n",
        "\n",
        "Heaps can be broadly classified into two types:\n",
        "\n",
        "1. **Max-Heap:**\n",
        "   In a Max-Heap, the key at the root node is the greatest among the keys in all of its children. This property must be true recursively for all sub-trees in the binary tree.\n",
        "\n",
        "2. **Min-Heap:**\n",
        "   In a Min-Heap, the key at the root node is the minimum among the keys in all of its children. Similar to the Max-Heap, this property must be recursively true for all sub-trees in the binary tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBPouH17i6ro"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "\n",
        "def find_top_k_doc(k, dataset_dummy):\n",
        "    top_documents_heap = []  # List for the max heap\n",
        "\n",
        "    # Add the documents to the heap\n",
        "    for index, row in dataset_dummy.iterrows():\n",
        "        document_score = row['final_score']\n",
        "        document_info = (-document_score, index)  # Use negation for max heap\n",
        "        if len(top_documents_heap) < k:\n",
        "            heapq.heappush(top_documents_heap, document_info)\n",
        "        else:\n",
        "            # If the heap is already of size k, compare the score of the current document with the maximum score in the heap\n",
        "            max_score, max_index = -top_documents_heap[0][0], top_documents_heap[0][1]\n",
        "            if document_score > max_score:\n",
        "                heapq.heappop(top_documents_heap)\n",
        "                heapq.heappush(top_documents_heap, document_info)\n",
        "\n",
        "    # Indices of the top-k documents from the heap\n",
        "    top_documents_indices = [index for _, index in top_documents_heap]\n",
        "\n",
        "    # Top-k documents from the DataFrame\n",
        "    top_documents = dataset_dummy.loc[top_documents_indices]\n",
        "    return top_documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eLeR3Aii6ro"
      },
      "outputs": [],
      "source": [
        "def compute_new_score(dataset_dummy):\n",
        "\n",
        "  # Add the weighted_modality column\n",
        "  modality_binary = dataset['modality'].str.get_dummies(', ') #Dataset of binary values for each value of the modality\n",
        "  total_columns_modality = modality_binary.sum(axis=1) # Total per row of the ones\n",
        "  weighted_total_modality = (\n",
        "      0.10 * modality_binary['MSc'] +    #Weight 'MSc' more\n",
        "      0.025 * modality_binary['Other'] +  # Weight 'Other' less\n",
        "      (1 - 0.10 - 0.025) * total_columns_modality  # Weight of other columns\n",
        "  )\n",
        "  dataset_dummy['weighted_modality'] = weighted_total_modality / total_columns_modality # Add the column to the dataset\n",
        "\n",
        "  # Add the weighted_administration column\n",
        "  administration_binary = dataset['administration'].str.get_dummies(', ')\n",
        "  total_columns_administration = administration_binary.sum(axis=1)\n",
        "  dataset_dummy['weighted_administration'] = total_columns_administration / administration_binary.shape[1]\n",
        "\n",
        "  # Add the weighted_startDate column\n",
        "  startDate_binary = dataset['startDate'].str.get_dummies(', ')\n",
        "  startDate_binary['total_columns_startDate'] = startDate_binary.sum(axis=1)\n",
        "  startDate_binary['weighted_total_startDate'] = (\n",
        "      0 * startDate_binary['See Course'] +  # Weight 'See Course' as 0\n",
        "      startDate_binary['total_columns_startDate']  # Weight other columns\n",
        "    )\n",
        "  startDate_binary.weighted_startDate = startDate_binary['weighted_total_startDate']  / startDate_binary['total_columns_startDate']\n",
        "  # Consider 'weighted_startDate' = 1 where in  dataset.startDate there is 'Any Month'\n",
        "  startDate_binary.loc[startDate_binary['Any Month'] == 1, 'weighted_startDate'] = 1\n",
        "  dataset_dummy['weighted_startDate'] = startDate_binary.weighted_startDate\n",
        "\n",
        "\n",
        "  selected_columns = ['courseName', 'universityName', 'description', 'url', 'weighted_modality', 'weighted_administration', 'weighted_startDate',  'similarity']\n",
        "  dataset_dummy = dataset_dummy[selected_columns]\n",
        "  dataset_dummy['final_score'] = dataset_dummy[['weighted_modality', 'weighted_administration', 'weighted_startDate', 'similarity']].mean(axis=1)\n",
        "\n",
        "  selected_columns = ['courseName', 'universityName', 'description', 'url', 'weighted_modality', 'weighted_administration', 'weighted_startDate', 'similarity']\n",
        "  dataset_dummy = dataset_dummy[selected_columns]\n",
        "  dataset_dummy['final_score'] = dataset_dummy[['weighted_modality', 'weighted_administration', 'weighted_startDate', 'similarity']].mean(axis=1)\n",
        "\n",
        "  # Find the top-k documents\n",
        "  print(f'There are {len(dataset_dummy)} documents')\n",
        "  k = int(input(\"How many documents would you like to see?\"))\n",
        "  if k <= len(dataset_dummy):\n",
        "    return find_top_k_doc(k, dataset_dummy)\n",
        "  else:\n",
        "    print(\"You asked for too many documents, here are all of them\")\n",
        "    return find_top_k_doc(len(dataset_dummy), dataset_dummy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfzWBaRui6rp",
        "outputId": "ddcdb0d5-70d3-45f1-f55c-4c4c409e5773"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_9948\\1124025670.py:25: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  startDate_binary.weighted_startDate = startDate_binary['weighted_total_startDate']  / startDate_binary['total_columns_startDate']\n",
            "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_9948\\1124025670.py:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset_dummy['final_score'] = dataset_dummy[['weighted_modality', 'weighted_administration', 'weighted_startDate', 'similarity']].mean(axis=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 20 documents\n"
          ]
        }
      ],
      "source": [
        "new_score_results= compute_new_score(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMpzp65Ri6rq",
        "outputId": "752616af-63ba-4526-88f4-2f06ed8778d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>courseName</th>\n",
              "      <th>universityName</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "      <th>weighted_modality</th>\n",
              "      <th>weighted_administration</th>\n",
              "      <th>weighted_startDate</th>\n",
              "      <th>similarity</th>\n",
              "      <th>final_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4462</th>\n",
              "      <td>Improvement Science - MSc</td>\n",
              "      <td>University of West London</td>\n",
              "      <td>Do you work in the health sector? Is there an ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.206</td>\n",
              "      <td>0.79525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5968</th>\n",
              "      <td>Master's of Data Science</td>\n",
              "      <td>Harbour.Space University</td>\n",
              "      <td>Harbour.Space’s Master of Data Science prepare...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.74375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5972</th>\n",
              "      <td>Master's of Front-end Development</td>\n",
              "      <td>Harbour.Space University</td>\n",
              "      <td>Front-end Development at Harbour.Space Univers...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.74375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5976</th>\n",
              "      <td>Masters's in Digital Politics and Governance</td>\n",
              "      <td>European School of Political and Social Scienc...</td>\n",
              "      <td>Digitalisation is a critical issue in today’s ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.74375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5969</th>\n",
              "      <td>Masters of Finance</td>\n",
              "      <td>University of Hong Kong</td>\n",
              "      <td>The HKU Business School Master of Finance (MFi...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.74375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5975</th>\n",
              "      <td>Masters Program in Climate Change, Agriculture...</td>\n",
              "      <td>University of Galway</td>\n",
              "      <td>The world’s climate is rapidly changing due to...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.74375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>Master's of Financial Technology (Fintech)</td>\n",
              "      <td>Harbour.Space University</td>\n",
              "      <td>Harbour.Space's FinTech Master programme is de...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.73125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5974</th>\n",
              "      <td>Masters of Science in Business, Supply Chain A...</td>\n",
              "      <td>Oregon State University</td>\n",
              "      <td>Master of Science in Business (MSB)Our Master ...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.49375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>Masters Of Finance (International Finance)</td>\n",
              "      <td>Zhejiang Gongshan University</td>\n",
              "      <td>Master’s in Finance (International Finance) at...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.73125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5973</th>\n",
              "      <td>Masters of Science in Business</td>\n",
              "      <td>Oregon State University</td>\n",
              "      <td>Our Master of Science in Business (MSB) will g...</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.48125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             courseName  \\\n",
              "4462                          Improvement Science - MSc   \n",
              "5968                           Master's of Data Science   \n",
              "5972                  Master's of Front-end Development   \n",
              "5976       Masters's in Digital Politics and Governance   \n",
              "5969                                 Masters of Finance   \n",
              "5975  Masters Program in Climate Change, Agriculture...   \n",
              "5971         Master's of Financial Technology (Fintech)   \n",
              "5974  Masters of Science in Business, Supply Chain A...   \n",
              "5970         Masters Of Finance (International Finance)   \n",
              "5973                     Masters of Science in Business   \n",
              "\n",
              "                                         universityName  \\\n",
              "4462                          University of West London   \n",
              "5968                           Harbour.Space University   \n",
              "5972                           Harbour.Space University   \n",
              "5976  European School of Political and Social Scienc...   \n",
              "5969                            University of Hong Kong   \n",
              "5975                               University of Galway   \n",
              "5971                           Harbour.Space University   \n",
              "5974                            Oregon State University   \n",
              "5970                       Zhejiang Gongshan University   \n",
              "5973                            Oregon State University   \n",
              "\n",
              "                                            description  \\\n",
              "4462  Do you work in the health sector? Is there an ...   \n",
              "5968  Harbour.Space’s Master of Data Science prepare...   \n",
              "5972  Front-end Development at Harbour.Space Univers...   \n",
              "5976  Digitalisation is a critical issue in today’s ...   \n",
              "5969  The HKU Business School Master of Finance (MFi...   \n",
              "5975  The world’s climate is rapidly changing due to...   \n",
              "5971  Harbour.Space's FinTech Master programme is de...   \n",
              "5974  Master of Science in Business (MSB)Our Master ...   \n",
              "5970  Master’s in Finance (International Finance) at...   \n",
              "5973  Our Master of Science in Business (MSB) will g...   \n",
              "\n",
              "                                                    url  weighted_modality  \\\n",
              "4462  https://www.findamasters.com/masters-degrees/c...              0.975   \n",
              "5968  https://www.findamasters.com/masters-degrees/c...              0.975   \n",
              "5972  https://www.findamasters.com/masters-degrees/c...              0.975   \n",
              "5976  https://www.findamasters.com/masters-degrees/c...              0.975   \n",
              "5969  https://www.findamasters.com/masters-degrees/c...              0.975   \n",
              "5975  https://www.findamasters.com/masters-degrees/c...              0.975   \n",
              "5971  https://www.findamasters.com/masters-degrees/c...              0.925   \n",
              "5974  https://www.findamasters.com/masters-degrees/c...              0.975   \n",
              "5970  https://www.findamasters.com/masters-degrees/c...              0.925   \n",
              "5973  https://www.findamasters.com/masters-degrees/c...              0.925   \n",
              "\n",
              "      weighted_administration  weighted_startDate  similarity  final_score  \n",
              "4462                      1.0                 1.0       0.206      0.79525  \n",
              "5968                      1.0                 1.0       0.000      0.74375  \n",
              "5972                      1.0                 1.0       0.000      0.74375  \n",
              "5976                      1.0                 1.0       0.000      0.74375  \n",
              "5969                      1.0                 1.0       0.000      0.74375  \n",
              "5975                      1.0                 1.0       0.000      0.74375  \n",
              "5971                      1.0                 1.0       0.000      0.73125  \n",
              "5974                      0.0                 1.0       0.000      0.49375  \n",
              "5970                      1.0                 1.0       0.000      0.73125  \n",
              "5973                      0.0                 1.0       0.000      0.48125  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_score_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XktBMk7i6rq"
      },
      "source": [
        "# 4. Visualizing the most relevant MSc degrees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWadxaINi6rr"
      },
      "source": [
        "From the dataset of the courese with the score found in the point 3 of the Homework, we create another dataset called 'geo' that contains the necessary columns to create the map of the masters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aORCa-Kfi6rr",
        "outputId": "5fabb1d3-096b-4353-c5f5-f8df21c59378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        courseName            universityName  \\\n",
            "11  Masters of Science in Business   Oregon State University   \n",
            "14    Master's of Computer Science  Harbour.Space University   \n",
            "\n",
            "           facultyName       city country  fees (EUR)  \n",
            "11  School of Business  Corvallis     USA  419.493908  \n",
            "14  Masters Programmes  Barcelona   Spain   17.806935  \n"
          ]
        }
      ],
      "source": [
        "#Creating the dataset with the k=6 most relevant MSc degrees\n",
        "df3 = dataset[['courseName', 'universityName', 'facultyName', 'city', 'country', 'fees (EUR)']]\n",
        "df3_score = new_score_results[['courseName']]\n",
        "\n",
        "geo = pd.merge(df3_score, df3, on=['courseName'], how='inner')\n",
        "geo = geo[geo['fees (EUR)'] != 'EUR']\n",
        "geo = geo[geo['fees (EUR)'].notna()]\n",
        "\n",
        "print(geo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okt0Tkf3i6rs"
      },
      "source": [
        "Now through the library geopy we find the corrispondent coordinates (latitude and longitude) and add them to the dataset geo.\\\n",
        "The function *get_ccordinates* is defined in the *defs* file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqsnShWfi6rs",
        "outputId": "9a15e017-8da6-48b9-fbe1-9a94f5883a7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        courseName            universityName  \\\n",
            "11  Masters of Science in Business   Oregon State University   \n",
            "14    Master's of Computer Science  Harbour.Space University   \n",
            "\n",
            "           facultyName       city country  fees (EUR)   latitude   longitude  \n",
            "11  School of Business  Corvallis     USA  419.493908  44.563056 -123.283924  \n",
            "14  Masters Programmes  Barcelona   Spain   17.806935  41.382894    2.177432  \n"
          ]
        }
      ],
      "source": [
        "#Finding the coordinates\n",
        "\n",
        "geo.loc[:, 'latitude'], geo.loc[:, 'longitude'] = zip(*geo.apply(lambda row: get_coordinates(row['universityName'], row['city'], row['country']), axis=1))\n",
        "#Printing the dataset\n",
        "print(geo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UxnMlpSi6rs"
      },
      "source": [
        "Finally we create the map with a color legend based on the fees, showwing the map about the courses and the associated taxation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cla_YK4li6rt",
        "outputId": "846417b1-0458-436c-c11b-45800311769c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_683848098190eebf4849af668118691f {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.markercluster/1.1.0/leaflet.markercluster.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.markercluster/1.1.0/MarkerCluster.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.markercluster/1.1.0/MarkerCluster.Default.css&quot;/&gt;\n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_683848098190eebf4849af668118691f&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_683848098190eebf4849af668118691f = L.map(\n",
              "                &quot;map_683848098190eebf4849af668118691f&quot;,\n",
              "                {\n",
              "                    center: [42.972974925, -60.55324571697876],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 2,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_97c02fadbc6ee465438de5fbec3a9b81 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                tile_layer_97c02fadbc6ee465438de5fbec3a9b81.addTo(map_683848098190eebf4849af668118691f);\n",
              "    \n",
              "    var color_map_edbd248e570670018837219b89edf2d6 = {};\n",
              "\n",
              "    \n",
              "    color_map_edbd248e570670018837219b89edf2d6.color = d3.scale.threshold()\n",
              "              .domain([2500.0, 2545.0901803607217, 2590.180360721443, 2635.2705410821645, 2680.3607214428857, 2725.4509018036074, 2770.5410821643286, 2815.6312625250503, 2860.7214428857715, 2905.811623246493, 2950.9018036072143, 2995.991983967936, 3041.082164328657, 3086.172344689379, 3131.2625250501, 3176.3527054108217, 3221.442885771543, 3266.5330661322646, 3311.6232464929863, 3356.7134268537075, 3401.8036072144287, 3446.8937875751503, 3491.983967935872, 3537.074148296593, 3582.1643286573144, 3627.254509018036, 3672.3446893787577, 3717.434869739479, 3762.5250501002, 3807.615230460922, 3852.7054108216435, 3897.7955911823647, 3942.885771543086, 3987.9759519038075, 4033.066132264529, 4078.1563126252504, 4123.2464929859725, 4168.336673346694, 4213.426853707415, 4258.517034068136, 4303.607214428857, 4348.697394789579, 4393.787575150301, 4438.877755511022, 4483.967935871744, 4529.058116232465, 4574.148296593186, 4619.238476953908, 4664.328657314629, 4709.418837675351, 4754.509018036072, 4799.599198396794, 4844.689378757515, 4889.779559118237, 4934.869739478958, 4979.959919839679, 5025.0501002004, 5070.140280561122, 5115.230460921844, 5160.320641282566, 5205.410821643287, 5250.501002004008, 5295.591182364729, 5340.6813627254505, 5385.771543086172, 5430.861723446894, 5475.951903807615, 5521.042084168337, 5566.132264529058, 5611.22244488978, 5656.312625250501, 5701.402805611222, 5746.492985971944, 5791.583166332665, 5836.673346693387, 5881.763527054109, 5926.85370741483, 5971.943887775551, 6017.034068136272, 6062.1242484969935, 6107.214428857716, 6152.304609218437, 6197.394789579159, 6242.48496993988, 6287.575150300601, 6332.6653306613225, 6377.755511022044, 6422.845691382765, 6467.935871743487, 6513.026052104208, 6558.11623246493, 6603.206412825652, 6648.296593186373, 6693.386773547094, 6738.476953907815, 6783.567134268537, 6828.6573146292585, 6873.74749498998, 6918.837675350702, 6963.927855711423, 7009.018036072144, 7054.108216432865, 7099.198396793588, 7144.288577154309, 7189.37875751503, 7234.468937875751, 7279.559118236473, 7324.6492985971945, 7369.739478957916, 7414.829659318637, 7459.919839679359, 7505.01002004008, 7550.100200400801, 7595.190380761523, 7640.280561122245, 7685.370741482966, 7730.460921843687, 7775.551102204408, 7820.6412825651305, 7865.731462925852, 7910.821643286573, 7955.911823647295, 8001.002004008016, 8046.092184368737, 8091.182364729459, 8136.272545090181, 8181.362725450902, 8226.452905811624, 8271.543086172343, 8316.633266533066, 8361.723446893788, 8406.813627254509, 8451.90380761523, 8496.993987975951, 8542.084168336674, 8587.174348697394, 8632.264529058117, 8677.354709418838, 8722.44488977956, 8767.53507014028, 8812.625250501002, 8857.715430861725, 8902.805611222444, 8947.895791583167, 8992.985971943888, 9038.07615230461, 9083.16633266533, 9128.256513026052, 9173.346693386775, 9218.436873747494, 9263.527054108217, 9308.617234468937, 9353.70741482966, 9398.79759519038, 9443.887775551102, 9488.977955911823, 9534.068136272545, 9579.158316633268, 9624.248496993987, 9669.33867735471, 9714.428857715431, 9759.519038076152, 9804.609218436874, 9849.699398797595, 9894.789579158318, 9939.879759519037, 9984.96993987976, 10030.060120240481, 10075.150300601203, 10120.240480961924, 10165.330661322645, 10210.420841683368, 10255.511022044087, 10300.60120240481, 10345.69138276553, 10390.781563126253, 10435.871743486974, 10480.961923847695, 10526.052104208416, 10571.142284569138, 10616.23246492986, 10661.32264529058, 10706.412825651303, 10751.503006012024, 10796.593186372746, 10841.683366733467, 10886.773547094188, 10931.86372745491, 10976.95390781563, 11022.044088176353, 11067.134268537075, 11112.224448897796, 11157.314629258517, 11202.404809619238, 11247.49498997996, 11292.58517034068, 11337.675350701404, 11382.765531062125, 11427.855711422846, 11472.945891783567, 11518.036072144288, 11563.12625250501, 11608.21643286573, 11653.306613226452, 11698.396793587175, 11743.486973947896, 11788.577154308618, 11833.667334669339, 11878.75751503006, 11923.847695390781, 11968.937875751502, 12014.028056112224, 12059.118236472947, 12104.208416833668, 12149.298597194389, 12194.38877755511, 12239.478957915831, 12284.569138276553, 12329.659318637274, 12374.749498997997, 12419.839679358718, 12464.92985971944, 12510.02004008016, 12555.110220440882, 12600.200400801603, 12645.290581162324, 12690.380761523045, 12735.470941883768, 12780.56112224449, 12825.65130260521, 12870.741482965932, 12915.831663326653, 12960.921843687374, 13006.012024048096, 13051.102204408817, 13096.19238476954, 13141.282565130261, 13186.372745490982, 13231.462925851703, 13276.553106212425, 13321.643286573146, 13366.733466933867, 13411.82364729459, 13456.913827655311, 13502.004008016032, 13547.094188376754, 13592.184368737475, 13637.274549098196, 13682.364729458917, 13727.454909819638, 13772.545090180362, 13817.635270541083, 13862.725450901804, 13907.815631262525, 13952.905811623246, 13997.995991983968, 14043.086172344689, 14088.17635270541, 14133.266533066133, 14178.356713426854, 14223.446893787575, 14268.537074148297, 14313.627254509018, 14358.717434869739, 14403.80761523046, 14448.897795591183, 14493.987975951904, 14539.078156312626, 14584.168336673347, 14629.258517034068, 14674.34869739479, 14719.43887775551, 14764.529058116232, 14809.619238476955, 14854.709418837676, 14899.799599198397, 14944.889779559118, 14989.97995991984, 15035.07014028056, 15080.160320641282, 15125.250501002003, 15170.340681362726, 15215.430861723447, 15260.521042084169, 15305.61122244489, 15350.701402805611, 15395.791583166332, 15440.881763527053, 15485.971943887776, 15531.062124248498, 15576.152304609219, 15621.24248496994, 15666.332665330661, 15711.422845691382, 15756.513026052104, 15801.603206412825, 15846.693386773548, 15891.78356713427, 15936.87374749499, 15981.963927855712, 16027.054108216433, 16072.144288577154, 16117.234468937875, 16162.324649298596, 16207.41482965932, 16252.50501002004, 16297.595190380762, 16342.685370741483, 16387.775551102204, 16432.865731462924, 16477.955911823647, 16523.04609218437, 16568.13627254509, 16613.226452905812, 16658.316633266535, 16703.406813627254, 16748.496993987974, 16793.587174348697, 16838.67735470942, 16883.76753507014, 16928.857715430862, 16973.947895791585, 17019.038076152305, 17064.128256513024, 17109.218436873747, 17154.30861723447, 17199.39879759519, 17244.488977955913, 17289.579158316636, 17334.669338677355, 17379.759519038074, 17424.849699398797, 17469.93987975952, 17515.03006012024, 17560.120240480963, 17605.210420841686, 17650.300601202405, 17695.390781563125, 17740.480961923848, 17785.57114228457, 17830.66132264529, 17875.75150300601, 17920.841683366736, 17965.931863727455, 18011.022044088175, 18056.112224448898, 18101.20240480962, 18146.29258517034, 18191.38276553106, 18236.472945891783, 18281.563126252506, 18326.653306613225, 18371.743486973948, 18416.83366733467, 18461.92384769539, 18507.01402805611, 18552.104208416833, 18597.194388777556, 18642.284569138275, 18687.374749499, 18732.46492985972, 18777.55511022044, 18822.64529058116, 18867.735470941883, 18912.825651302606, 18957.915831663326, 19003.00601202405, 19048.096192384768, 19093.18637274549, 19138.276553106214, 19183.366733466934, 19228.456913827657, 19273.547094188376, 19318.6372745491, 19363.72745490982, 19408.81763527054, 19453.90781563126, 19498.997995991984, 19544.088176352707, 19589.178356713426, 19634.26853707415, 19679.35871743487, 19724.44889779559, 19769.53907815631, 19814.629258517034, 19859.719438877757, 19904.809619238476, 19949.8997995992, 19994.98997995992, 20040.080160320642, 20085.17034068136, 20130.260521042084, 20175.350701402807, 20220.440881763527, 20265.53106212425, 20310.62124248497, 20355.711422845692, 20400.80160320641, 20445.891783567135, 20490.981963927854, 20536.072144288577, 20581.1623246493, 20626.25250501002, 20671.342685370742, 20716.43286573146, 20761.523046092185, 20806.613226452904, 20851.703406813627, 20896.79358717435, 20941.88376753507, 20986.973947895793, 21032.064128256512, 21077.154308617235, 21122.244488977954, 21167.334669338677, 21212.4248496994, 21257.51503006012, 21302.605210420843, 21347.695390781562, 21392.785571142285, 21437.875751503005, 21482.965931863728, 21528.056112224447, 21573.14629258517, 21618.236472945893, 21663.326653306613, 21708.416833667336, 21753.507014028055, 21798.597194388778, 21843.687374749497, 21888.77755511022, 21933.867735470943, 21978.957915831663, 22024.048096192386, 22069.138276553105, 22114.22845691383, 22159.318637274548, 22204.40881763527, 22249.498997995994, 22294.589178356713, 22339.679358717436, 22384.769539078156, 22429.85971943888, 22474.949899799598, 22520.04008016032, 22565.13026052104, 22610.220440881763, 22655.310621242486, 22700.400801603206, 22745.49098196393, 22790.581162324648, 22835.67134268537, 22880.76152304609, 22925.851703406814, 22970.941883767537, 23016.032064128256, 23061.12224448898, 23106.2124248497, 23151.30260521042, 23196.39278557114, 23241.482965931864, 23286.573146292587, 23331.663326653306, 23376.75350701403, 23421.84368737475, 23466.93386773547, 23512.02404809619, 23557.114228456914, 23602.204408817634, 23647.294589178357, 23692.38476953908, 23737.4749498998, 23782.565130260522, 23827.65531062124, 23872.745490981964, 23917.835671342684, 23962.925851703407, 24008.01603206413, 24053.10621242485, 24098.196392785572, 24143.28657314629, 24188.376753507015, 24233.466933867734, 24278.557114228457, 24323.64729458918, 24368.7374749499, 24413.827655310623, 24458.917835671342, 24504.008016032065, 24549.098196392784, 24594.188376753507, 24639.278557114227, 24684.36873747495, 24729.458917835673, 24774.549098196392, 24819.639278557115, 24864.729458917835, 24909.819639278558, 24954.909819639277, 25000.0])\n",
              "              .range([&#x27;#0000ffff&#x27;, &#x27;#0004ffff&#x27;, &#x27;#0009ffff&#x27;, &#x27;#000dffff&#x27;, &#x27;#0012ffff&#x27;, &#x27;#0017ffff&#x27;, &#x27;#001bffff&#x27;, &#x27;#0020ffff&#x27;, &#x27;#0024ffff&#x27;, &#x27;#0029ffff&#x27;, &#x27;#002effff&#x27;, &#x27;#0032ffff&#x27;, &#x27;#0037ffff&#x27;, &#x27;#003cffff&#x27;, &#x27;#0040ffff&#x27;, &#x27;#0045ffff&#x27;, &#x27;#0049ffff&#x27;, &#x27;#004effff&#x27;, &#x27;#0053ffff&#x27;, &#x27;#0057ffff&#x27;, &#x27;#005cffff&#x27;, &#x27;#0060ffff&#x27;, &#x27;#0065ffff&#x27;, &#x27;#006affff&#x27;, &#x27;#006effff&#x27;, &#x27;#0073ffff&#x27;, &#x27;#0078ffff&#x27;, &#x27;#007cffff&#x27;, &#x27;#0081ffff&#x27;, &#x27;#0085ffff&#x27;, &#x27;#008affff&#x27;, &#x27;#008fffff&#x27;, &#x27;#0093ffff&#x27;, &#x27;#0098ffff&#x27;, &#x27;#009cffff&#x27;, &#x27;#00a1ffff&#x27;, &#x27;#00a6ffff&#x27;, &#x27;#00aaffff&#x27;, &#x27;#00afffff&#x27;, &#x27;#00b4ffff&#x27;, &#x27;#00b8ffff&#x27;, &#x27;#00bdffff&#x27;, &#x27;#00c1ffff&#x27;, &#x27;#00c6ffff&#x27;, &#x27;#00cbffff&#x27;, &#x27;#00cfffff&#x27;, &#x27;#00d4ffff&#x27;, &#x27;#00d9ffff&#x27;, &#x27;#00ddffff&#x27;, &#x27;#00e2ffff&#x27;, &#x27;#00e6ffff&#x27;, &#x27;#00ebffff&#x27;, &#x27;#00f0ffff&#x27;, &#x27;#00f4ffff&#x27;, &#x27;#00f9ffff&#x27;, &#x27;#00fdffff&#x27;, &#x27;#00fefdff&#x27;, &#x27;#00fcf8ff&#x27;, &#x27;#00faf4ff&#x27;, &#x27;#00f7efff&#x27;, &#x27;#00f5eaff&#x27;, &#x27;#00f3e6ff&#x27;, &#x27;#00f0e1ff&#x27;, &#x27;#00eeddff&#x27;, &#x27;#00ecd8ff&#x27;, &#x27;#00ead3ff&#x27;, &#x27;#00e7cfff&#x27;, &#x27;#00e5caff&#x27;, &#x27;#00e3c6ff&#x27;, &#x27;#00e0c1ff&#x27;, &#x27;#00debcff&#x27;, &#x27;#00dcb8ff&#x27;, &#x27;#00d9b3ff&#x27;, &#x27;#00d7aeff&#x27;, &#x27;#00d5aaff&#x27;, &#x27;#00d3a5ff&#x27;, &#x27;#00d0a1ff&#x27;, &#x27;#00ce9cff&#x27;, &#x27;#00cc97ff&#x27;, &#x27;#00c993ff&#x27;, &#x27;#00c78eff&#x27;, &#x27;#00c58aff&#x27;, &#x27;#00c285ff&#x27;, &#x27;#00c080ff&#x27;, &#x27;#00be7cff&#x27;, &#x27;#00bc77ff&#x27;, &#x27;#00b972ff&#x27;, &#x27;#00b76eff&#x27;, &#x27;#00b569ff&#x27;, &#x27;#00b265ff&#x27;, &#x27;#00b060ff&#x27;, &#x27;#00ae5bff&#x27;, &#x27;#00ab57ff&#x27;, &#x27;#00a952ff&#x27;, &#x27;#00a74dff&#x27;, &#x27;#00a549ff&#x27;, &#x27;#00a244ff&#x27;, &#x27;#00a040ff&#x27;, &#x27;#009e3bff&#x27;, &#x27;#009b36ff&#x27;, &#x27;#009932ff&#x27;, &#x27;#00972dff&#x27;, &#x27;#009429ff&#x27;, &#x27;#009224ff&#x27;, &#x27;#00901fff&#x27;, &#x27;#008e1bff&#x27;, &#x27;#008b16ff&#x27;, &#x27;#008911ff&#x27;, &#x27;#00870dff&#x27;, &#x27;#008408ff&#x27;, &#x27;#008204ff&#x27;, &#x27;#008000ff&#x27;, &#x27;#058300ff&#x27;, &#x27;#098500ff&#x27;, &#x27;#0e8700ff&#x27;, &#x27;#128900ff&#x27;, &#x27;#178c00ff&#x27;, &#x27;#1c8e00ff&#x27;, &#x27;#209000ff&#x27;, &#x27;#259300ff&#x27;, &#x27;#2a9500ff&#x27;, &#x27;#2e9700ff&#x27;, &#x27;#339a00ff&#x27;, &#x27;#379c00ff&#x27;, &#x27;#3c9e00ff&#x27;, &#x27;#41a000ff&#x27;, &#x27;#45a300ff&#x27;, &#x27;#4aa500ff&#x27;, &#x27;#4fa700ff&#x27;, &#x27;#53aa00ff&#x27;, &#x27;#58ac00ff&#x27;, &#x27;#5cae00ff&#x27;, &#x27;#61b100ff&#x27;, &#x27;#66b300ff&#x27;, &#x27;#6ab500ff&#x27;, &#x27;#6fb700ff&#x27;, &#x27;#73ba00ff&#x27;, &#x27;#78bc00ff&#x27;, &#x27;#7dbe00ff&#x27;, &#x27;#81c100ff&#x27;, &#x27;#86c300ff&#x27;, &#x27;#8bc500ff&#x27;, &#x27;#8fc800ff&#x27;, &#x27;#94ca00ff&#x27;, &#x27;#98cc00ff&#x27;, &#x27;#9dce00ff&#x27;, &#x27;#a2d100ff&#x27;, &#x27;#a6d300ff&#x27;, &#x27;#abd500ff&#x27;, &#x27;#afd800ff&#x27;, &#x27;#b4da00ff&#x27;, &#x27;#b9dc00ff&#x27;, &#x27;#bddf00ff&#x27;, &#x27;#c2e100ff&#x27;, &#x27;#c7e300ff&#x27;, &#x27;#cbe500ff&#x27;, &#x27;#d0e800ff&#x27;, &#x27;#d4ea00ff&#x27;, &#x27;#d9ec00ff&#x27;, &#x27;#deef00ff&#x27;, &#x27;#e2f100ff&#x27;, &#x27;#e7f300ff&#x27;, &#x27;#ebf600ff&#x27;, &#x27;#f0f800ff&#x27;, &#x27;#f5fa00ff&#x27;, &#x27;#f9fc00ff&#x27;, &#x27;#feff00ff&#x27;, &#x27;#fffe00ff&#x27;, &#x27;#fffd00ff&#x27;, &#x27;#fffb00ff&#x27;, &#x27;#fffa00ff&#x27;, &#x27;#fff800ff&#x27;, &#x27;#fff600ff&#x27;, &#x27;#fff500ff&#x27;, &#x27;#fff300ff&#x27;, &#x27;#fff100ff&#x27;, &#x27;#fff000ff&#x27;, &#x27;#ffee00ff&#x27;, &#x27;#ffec00ff&#x27;, &#x27;#ffeb00ff&#x27;, &#x27;#ffe900ff&#x27;, &#x27;#ffe800ff&#x27;, &#x27;#ffe600ff&#x27;, &#x27;#ffe400ff&#x27;, &#x27;#ffe300ff&#x27;, &#x27;#ffe100ff&#x27;, &#x27;#ffdf00ff&#x27;, &#x27;#ffde00ff&#x27;, &#x27;#ffdc00ff&#x27;, &#x27;#ffdb00ff&#x27;, &#x27;#ffd900ff&#x27;, &#x27;#ffd700ff&#x27;, &#x27;#ffd600ff&#x27;, &#x27;#ffd400ff&#x27;, &#x27;#ffd200ff&#x27;, &#x27;#ffd100ff&#x27;, &#x27;#ffcf00ff&#x27;, &#x27;#ffce00ff&#x27;, &#x27;#ffcc00ff&#x27;, &#x27;#ffca00ff&#x27;, &#x27;#ffc900ff&#x27;, &#x27;#ffc700ff&#x27;, &#x27;#ffc500ff&#x27;, &#x27;#ffc400ff&#x27;, &#x27;#ffc200ff&#x27;, &#x27;#ffc000ff&#x27;, &#x27;#ffbf00ff&#x27;, &#x27;#ffbd00ff&#x27;, &#x27;#ffbc00ff&#x27;, &#x27;#ffba00ff&#x27;, &#x27;#ffb800ff&#x27;, &#x27;#ffb700ff&#x27;, &#x27;#ffb500ff&#x27;, &#x27;#ffb300ff&#x27;, &#x27;#ffb200ff&#x27;, &#x27;#ffb000ff&#x27;, &#x27;#ffaf00ff&#x27;, &#x27;#ffad00ff&#x27;, &#x27;#ffab00ff&#x27;, &#x27;#ffaa00ff&#x27;, &#x27;#ffa800ff&#x27;, &#x27;#ffa600ff&#x27;, &#x27;#ffa400ff&#x27;, &#x27;#ffa100ff&#x27;, &#x27;#ff9f00ff&#x27;, &#x27;#ff9c00ff&#x27;, &#x27;#ff9900ff&#x27;, &#x27;#ff9600ff&#x27;, &#x27;#ff9300ff&#x27;, &#x27;#ff9000ff&#x27;, &#x27;#ff8d00ff&#x27;, &#x27;#ff8a00ff&#x27;, &#x27;#ff8700ff&#x27;, &#x27;#ff8400ff&#x27;, &#x27;#ff8100ff&#x27;, &#x27;#ff7e00ff&#x27;, &#x27;#ff7b00ff&#x27;, &#x27;#ff7800ff&#x27;, &#x27;#ff7500ff&#x27;, &#x27;#ff7200ff&#x27;, &#x27;#ff6f00ff&#x27;, &#x27;#ff6c00ff&#x27;, &#x27;#ff6900ff&#x27;, &#x27;#ff6600ff&#x27;, &#x27;#ff6300ff&#x27;, &#x27;#ff6000ff&#x27;, &#x27;#ff5d00ff&#x27;, &#x27;#ff5a00ff&#x27;, &#x27;#ff5700ff&#x27;, &#x27;#ff5400ff&#x27;, &#x27;#ff5100ff&#x27;, &#x27;#ff4e00ff&#x27;, &#x27;#ff4b00ff&#x27;, &#x27;#ff4800ff&#x27;, &#x27;#ff4500ff&#x27;, &#x27;#ff4200ff&#x27;, &#x27;#ff3f00ff&#x27;, &#x27;#ff3c00ff&#x27;, &#x27;#ff3900ff&#x27;, &#x27;#ff3600ff&#x27;, &#x27;#ff3300ff&#x27;, &#x27;#ff3000ff&#x27;, &#x27;#ff2d00ff&#x27;, &#x27;#ff2a00ff&#x27;, &#x27;#ff2700ff&#x27;, &#x27;#ff2400ff&#x27;, &#x27;#ff2100ff&#x27;, &#x27;#ff1e00ff&#x27;, &#x27;#ff1b00ff&#x27;, &#x27;#ff1800ff&#x27;, &#x27;#ff1500ff&#x27;, &#x27;#ff1200ff&#x27;, &#x27;#ff0f00ff&#x27;, &#x27;#ff0c00ff&#x27;, &#x27;#ff0900ff&#x27;, &#x27;#ff0600ff&#x27;, &#x27;#ff0300ff&#x27;, &#x27;#ff0000ff&#x27;, &#x27;#fe0001ff&#x27;, &#x27;#fb0004ff&#x27;, &#x27;#f90006ff&#x27;, &#x27;#f70008ff&#x27;, &#x27;#f5000bff&#x27;, &#x27;#f2000dff&#x27;, &#x27;#f0000fff&#x27;, &#x27;#ee0012ff&#x27;, &#x27;#eb0014ff&#x27;, &#x27;#e90016ff&#x27;, &#x27;#e70018ff&#x27;, &#x27;#e4001bff&#x27;, &#x27;#e2001dff&#x27;, &#x27;#e0001fff&#x27;, &#x27;#de0022ff&#x27;, &#x27;#db0024ff&#x27;, &#x27;#d90026ff&#x27;, &#x27;#d70029ff&#x27;, &#x27;#d4002bff&#x27;, &#x27;#d2002dff&#x27;, &#x27;#d00030ff&#x27;, &#x27;#cd0032ff&#x27;, &#x27;#cb0034ff&#x27;, &#x27;#c90037ff&#x27;, &#x27;#c70039ff&#x27;, &#x27;#c4003bff&#x27;, &#x27;#c2003eff&#x27;, &#x27;#c00040ff&#x27;, &#x27;#bd0042ff&#x27;, &#x27;#bb0045ff&#x27;, &#x27;#b90047ff&#x27;, &#x27;#b60049ff&#x27;, &#x27;#b4004bff&#x27;, &#x27;#b2004eff&#x27;, &#x27;#b00050ff&#x27;, &#x27;#ad0052ff&#x27;, &#x27;#ab0055ff&#x27;, &#x27;#a90057ff&#x27;, &#x27;#a60059ff&#x27;, &#x27;#a4005cff&#x27;, &#x27;#a2005eff&#x27;, &#x27;#9f0060ff&#x27;, &#x27;#9d0063ff&#x27;, &#x27;#9b0065ff&#x27;, &#x27;#990067ff&#x27;, &#x27;#96006aff&#x27;, &#x27;#94006cff&#x27;, &#x27;#92006eff&#x27;, &#x27;#8f0071ff&#x27;, &#x27;#8d0073ff&#x27;, &#x27;#8b0075ff&#x27;, &#x27;#880078ff&#x27;, &#x27;#86007aff&#x27;, &#x27;#84007cff&#x27;, &#x27;#82007eff&#x27;, &#x27;#810180ff&#x27;, &#x27;#830482ff&#x27;, &#x27;#850883ff&#x27;, &#x27;#880b85ff&#x27;, &#x27;#8a0f86ff&#x27;, &#x27;#8c1287ff&#x27;, &#x27;#8f1689ff&#x27;, &#x27;#91198aff&#x27;, &#x27;#931c8bff&#x27;, &#x27;#95208dff&#x27;, &#x27;#98238eff&#x27;, &#x27;#9a278fff&#x27;, &#x27;#9c2a91ff&#x27;, &#x27;#9f2e92ff&#x27;, &#x27;#a13193ff&#x27;, &#x27;#a33595ff&#x27;, &#x27;#a63896ff&#x27;, &#x27;#a83c98ff&#x27;, &#x27;#aa3f99ff&#x27;, &#x27;#ac439aff&#x27;, &#x27;#af469cff&#x27;, &#x27;#b14a9dff&#x27;, &#x27;#b34d9eff&#x27;, &#x27;#b651a0ff&#x27;, &#x27;#b854a1ff&#x27;, &#x27;#ba58a2ff&#x27;, &#x27;#bd5ba4ff&#x27;, &#x27;#bf5fa5ff&#x27;, &#x27;#c162a6ff&#x27;, &#x27;#c365a8ff&#x27;, &#x27;#c669a9ff&#x27;, &#x27;#c86cabff&#x27;, &#x27;#ca70acff&#x27;, &#x27;#cd73adff&#x27;, &#x27;#cf77afff&#x27;, &#x27;#d17ab0ff&#x27;, &#x27;#d47eb1ff&#x27;, &#x27;#d681b3ff&#x27;, &#x27;#d885b4ff&#x27;, &#x27;#da88b5ff&#x27;, &#x27;#dd8cb7ff&#x27;, &#x27;#df8fb8ff&#x27;, &#x27;#e193b9ff&#x27;, &#x27;#e496bbff&#x27;, &#x27;#e69abcff&#x27;, &#x27;#e89dbeff&#x27;, &#x27;#eba1bfff&#x27;, &#x27;#eda4c0ff&#x27;, &#x27;#efa8c2ff&#x27;, &#x27;#f1abc3ff&#x27;, &#x27;#f4aec4ff&#x27;, &#x27;#f6b2c6ff&#x27;, &#x27;#f8b5c7ff&#x27;, &#x27;#fbb9c8ff&#x27;, &#x27;#fdbccaff&#x27;, &#x27;#ffc0cbff&#x27;, &#x27;#febec9ff&#x27;, &#x27;#fcbbc6ff&#x27;, &#x27;#fbb8c3ff&#x27;, &#x27;#f9b6c0ff&#x27;, &#x27;#f8b3bdff&#x27;, &#x27;#f6b0baff&#x27;, &#x27;#f4aeb7ff&#x27;, &#x27;#f3abb4ff&#x27;, &#x27;#f1a8b1ff&#x27;, &#x27;#efa5aeff&#x27;, &#x27;#eea3acff&#x27;, &#x27;#eca0a9ff&#x27;, &#x27;#ea9da6ff&#x27;, &#x27;#e99ba3ff&#x27;, &#x27;#e798a0ff&#x27;, &#x27;#e6959dff&#x27;, &#x27;#e4929aff&#x27;, &#x27;#e29097ff&#x27;, &#x27;#e18d94ff&#x27;, &#x27;#df8a91ff&#x27;, &#x27;#dd888eff&#x27;, &#x27;#dc858bff&#x27;, &#x27;#da8289ff&#x27;, &#x27;#d97f86ff&#x27;, &#x27;#d77d83ff&#x27;, &#x27;#d57a80ff&#x27;, &#x27;#d4777dff&#x27;, &#x27;#d2757aff&#x27;, &#x27;#d07277ff&#x27;, &#x27;#cf6f74ff&#x27;, &#x27;#cd6c71ff&#x27;, &#x27;#cc6a6eff&#x27;, &#x27;#ca676bff&#x27;, &#x27;#c86469ff&#x27;, &#x27;#c76166ff&#x27;, &#x27;#c55f63ff&#x27;, &#x27;#c35c60ff&#x27;, &#x27;#c2595dff&#x27;, &#x27;#c0575aff&#x27;, &#x27;#be5457ff&#x27;, &#x27;#bd5154ff&#x27;, &#x27;#bb4e51ff&#x27;, &#x27;#ba4c4eff&#x27;, &#x27;#b8494bff&#x27;, &#x27;#b64648ff&#x27;, &#x27;#b54446ff&#x27;, &#x27;#b34143ff&#x27;, &#x27;#b13e40ff&#x27;, &#x27;#b03b3dff&#x27;, &#x27;#ae393aff&#x27;, &#x27;#ad3637ff&#x27;, &#x27;#ab3334ff&#x27;, &#x27;#a93131ff&#x27;, &#x27;#a82e2eff&#x27;, &#x27;#a62b2bff&#x27;, &#x27;#a52a2aff&#x27;, &#x27;#a42c2cff&#x27;, &#x27;#a42d2dff&#x27;, &#x27;#a32f2fff&#x27;, &#x27;#a23131ff&#x27;, &#x27;#a13232ff&#x27;, &#x27;#a13434ff&#x27;, &#x27;#a03535ff&#x27;, &#x27;#9f3737ff&#x27;, &#x27;#9f3838ff&#x27;, &#x27;#9e3a3aff&#x27;, &#x27;#9d3b3bff&#x27;, &#x27;#9d3d3dff&#x27;, &#x27;#9c3f3fff&#x27;, &#x27;#9b4040ff&#x27;, &#x27;#9b4242ff&#x27;, &#x27;#9a4343ff&#x27;, &#x27;#994545ff&#x27;, &#x27;#994646ff&#x27;, &#x27;#984848ff&#x27;, &#x27;#974a4aff&#x27;, &#x27;#974b4bff&#x27;, &#x27;#964d4dff&#x27;, &#x27;#954e4eff&#x27;, &#x27;#955050ff&#x27;, &#x27;#945151ff&#x27;, &#x27;#935353ff&#x27;, &#x27;#935454ff&#x27;, &#x27;#925656ff&#x27;, &#x27;#915858ff&#x27;, &#x27;#915959ff&#x27;, &#x27;#905b5bff&#x27;, &#x27;#8f5c5cff&#x27;, &#x27;#8f5e5eff&#x27;, &#x27;#8e5f5fff&#x27;, &#x27;#8d6161ff&#x27;, &#x27;#8d6262ff&#x27;, &#x27;#8c6464ff&#x27;, &#x27;#8b6666ff&#x27;, &#x27;#8b6767ff&#x27;, &#x27;#8a6969ff&#x27;, &#x27;#896a6aff&#x27;, &#x27;#896c6cff&#x27;, &#x27;#886d6dff&#x27;, &#x27;#876f6fff&#x27;, &#x27;#877070ff&#x27;, &#x27;#867272ff&#x27;, &#x27;#857474ff&#x27;, &#x27;#857575ff&#x27;, &#x27;#847777ff&#x27;, &#x27;#837878ff&#x27;, &#x27;#837a7aff&#x27;, &#x27;#827b7bff&#x27;, &#x27;#817d7dff&#x27;, &#x27;#817e7eff&#x27;, &#x27;#808080ff&#x27;]);\n",
              "    \n",
              "\n",
              "    color_map_edbd248e570670018837219b89edf2d6.x = d3.scale.linear()\n",
              "              .domain([2500.0, 25000.0])\n",
              "              .range([0, 450 - 50]);\n",
              "\n",
              "    color_map_edbd248e570670018837219b89edf2d6.legend = L.control({position: &#x27;topright&#x27;});\n",
              "    color_map_edbd248e570670018837219b89edf2d6.legend.onAdd = function (map) {var div = L.DomUtil.create(&#x27;div&#x27;, &#x27;legend&#x27;); return div};\n",
              "    color_map_edbd248e570670018837219b89edf2d6.legend.addTo(map_683848098190eebf4849af668118691f);\n",
              "\n",
              "    color_map_edbd248e570670018837219b89edf2d6.xAxis = d3.svg.axis()\n",
              "        .scale(color_map_edbd248e570670018837219b89edf2d6.x)\n",
              "        .orient(&quot;top&quot;)\n",
              "        .tickSize(1)\n",
              "        .tickValues([2500, 5000, 7500, 10000, 12500, 15000, 17500, 20000, 22500, 25000]);\n",
              "\n",
              "    color_map_edbd248e570670018837219b89edf2d6.svg = d3.select(&quot;.legend.leaflet-control&quot;).append(&quot;svg&quot;)\n",
              "        .attr(&quot;id&quot;, &#x27;legend&#x27;)\n",
              "        .attr(&quot;width&quot;, 450)\n",
              "        .attr(&quot;height&quot;, 40);\n",
              "\n",
              "    color_map_edbd248e570670018837219b89edf2d6.g = color_map_edbd248e570670018837219b89edf2d6.svg.append(&quot;g&quot;)\n",
              "        .attr(&quot;class&quot;, &quot;key&quot;)\n",
              "        .attr(&quot;transform&quot;, &quot;translate(25,16)&quot;);\n",
              "\n",
              "    color_map_edbd248e570670018837219b89edf2d6.g.selectAll(&quot;rect&quot;)\n",
              "        .data(color_map_edbd248e570670018837219b89edf2d6.color.range().map(function(d, i) {\n",
              "          return {\n",
              "            x0: i ? color_map_edbd248e570670018837219b89edf2d6.x(color_map_edbd248e570670018837219b89edf2d6.color.domain()[i - 1]) : color_map_edbd248e570670018837219b89edf2d6.x.range()[0],\n",
              "            x1: i &lt; color_map_edbd248e570670018837219b89edf2d6.color.domain().length ? color_map_edbd248e570670018837219b89edf2d6.x(color_map_edbd248e570670018837219b89edf2d6.color.domain()[i]) : color_map_edbd248e570670018837219b89edf2d6.x.range()[1],\n",
              "            z: d\n",
              "          };\n",
              "        }))\n",
              "      .enter().append(&quot;rect&quot;)\n",
              "        .attr(&quot;height&quot;, 40 - 30)\n",
              "        .attr(&quot;x&quot;, function(d) { return d.x0; })\n",
              "        .attr(&quot;width&quot;, function(d) { return d.x1 - d.x0; })\n",
              "        .style(&quot;fill&quot;, function(d) { return d.z; });\n",
              "\n",
              "    color_map_edbd248e570670018837219b89edf2d6.g.call(color_map_edbd248e570670018837219b89edf2d6.xAxis).append(&quot;text&quot;)\n",
              "        .attr(&quot;class&quot;, &quot;caption&quot;)\n",
              "        .attr(&quot;y&quot;, 21)\n",
              "        .text(&quot;Tuition Fees (EUR)&quot;);\n",
              "    \n",
              "            var marker_cluster_424406815a2dd0f89196c59468ebf114 = L.markerClusterGroup(\n",
              "                {}\n",
              "            );\n",
              "        \n",
              "    \n",
              "            var marker_4f9a52317a60de2bb6a8e5d1dc0bd6ad = L.marker(\n",
              "                [44.56305595, -123.28392363395751],\n",
              "                {}\n",
              "            ).addTo(marker_cluster_424406815a2dd0f89196c59468ebf114);\n",
              "        \n",
              "    \n",
              "            var icon_bbe517d5570963286b965bd876a5d27d = L.AwesomeMarkers.icon(\n",
              "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;fa-location-dot&quot;, &quot;iconColor&quot;: &quot;#0000ffff&quot;, &quot;markerColor&quot;: &quot;white&quot;, &quot;prefix&quot;: &quot;fa&quot;}\n",
              "            );\n",
              "            marker_4f9a52317a60de2bb6a8e5d1dc0bd6ad.setIcon(icon_bbe517d5570963286b965bd876a5d27d);\n",
              "        \n",
              "    \n",
              "        var popup_7db7f7dfb7c920ee3420484a4af86cc4 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
              "\n",
              "        \n",
              "            \n",
              "                var html_f702db281cf1edc48b3d4fbf4cbb5f90 = $(`&lt;div id=&quot;html_f702db281cf1edc48b3d4fbf4cbb5f90&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Oregon State University - Course: Masters of Science in Business - Fees: 419&lt;/div&gt;`)[0];\n",
              "                popup_7db7f7dfb7c920ee3420484a4af86cc4.setContent(html_f702db281cf1edc48b3d4fbf4cbb5f90);\n",
              "            \n",
              "        \n",
              "\n",
              "        marker_4f9a52317a60de2bb6a8e5d1dc0bd6ad.bindPopup(popup_7db7f7dfb7c920ee3420484a4af86cc4)\n",
              "        ;\n",
              "\n",
              "        \n",
              "    \n",
              "    \n",
              "            marker_4f9a52317a60de2bb6a8e5d1dc0bd6ad.bindTooltip(\n",
              "                `&lt;div&gt;\n",
              "                     Oregon State University - Masters of Science in Business - 419.49390815370197\n",
              "                 &lt;/div&gt;`,\n",
              "                {&quot;sticky&quot;: true}\n",
              "            );\n",
              "        \n",
              "    \n",
              "            var marker_e43dca838db1df5f3b092891ebd58e6c = L.marker(\n",
              "                [41.3828939, 2.1774322],\n",
              "                {}\n",
              "            ).addTo(marker_cluster_424406815a2dd0f89196c59468ebf114);\n",
              "        \n",
              "    \n",
              "            var icon_1956d6f6c032290dff8418a4c59e1563 = L.AwesomeMarkers.icon(\n",
              "                {&quot;extraClasses&quot;: &quot;fa-rotate-0&quot;, &quot;icon&quot;: &quot;fa-location-dot&quot;, &quot;iconColor&quot;: &quot;#0000ffff&quot;, &quot;markerColor&quot;: &quot;white&quot;, &quot;prefix&quot;: &quot;fa&quot;}\n",
              "            );\n",
              "            marker_e43dca838db1df5f3b092891ebd58e6c.setIcon(icon_1956d6f6c032290dff8418a4c59e1563);\n",
              "        \n",
              "    \n",
              "        var popup_e1806bc9f7115d2602ccce1c877a8979 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
              "\n",
              "        \n",
              "            \n",
              "                var html_017597cbe29bbe11ba562b20bde39b8f = $(`&lt;div id=&quot;html_017597cbe29bbe11ba562b20bde39b8f&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Harbour.Space University - Course: Master&#x27;s of Computer Science - Fees: 17&lt;/div&gt;`)[0];\n",
              "                popup_e1806bc9f7115d2602ccce1c877a8979.setContent(html_017597cbe29bbe11ba562b20bde39b8f);\n",
              "            \n",
              "        \n",
              "\n",
              "        marker_e43dca838db1df5f3b092891ebd58e6c.bindPopup(popup_e1806bc9f7115d2602ccce1c877a8979)\n",
              "        ;\n",
              "\n",
              "        \n",
              "    \n",
              "    \n",
              "            marker_e43dca838db1df5f3b092891ebd58e6c.bindTooltip(\n",
              "                `&lt;div&gt;\n",
              "                     Harbour.Space University - Master&#x27;s of Computer Science - 17.80693533270853\n",
              "                 &lt;/div&gt;`,\n",
              "                {&quot;sticky&quot;: true}\n",
              "            );\n",
              "        \n",
              "    \n",
              "                marker_cluster_424406815a2dd0f89196c59468ebf114.addTo(map_683848098190eebf4849af668118691f);\n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x23805e149d0>"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "from folium.features import CustomIcon\n",
        "from branca.colormap import LinearColormap\n",
        "\n",
        "#Defining the tuition fee classes\n",
        "fee_classes = [2500, 5000, 7500, 10000, 12500, 15000, 17500, 20000, 22500, 25000] #10 classes of tuition fees\n",
        "fee_labels = [f\"{fee:,}-{fee_next:,}\" for fee, fee_next in zip(fee_classes, fee_classes[1:])]\n",
        "fee_labels[-1] = f\"{fee_classes[-1]:,}+\"\n",
        "\n",
        "#Creating a Folium map\n",
        "m = folium.Map(location=[geo['latitude'].mean(), geo['longitude'].mean()], zoom_start=2)\n",
        "\n",
        "#Creating a color scale for tuition fees\n",
        "colormap = LinearColormap(colors=['blue', 'cyan', 'green', 'yellow', 'orange', 'red', 'purple', 'pink', 'brown', 'gray'], index=fee_classes, vmin=fee_classes[0], vmax=fee_classes[-1])\n",
        "\n",
        "#Adding the legend to the map\n",
        "colormap.caption = 'Tuition Fees (EUR)'\n",
        "m.add_child(colormap)\n",
        "\n",
        "#Creating a MarkerCluster to group the markers\n",
        "marker_cluster = MarkerCluster().add_to(m)\n",
        "\n",
        "#Adding markers to the map for tuition fees\n",
        "for index, row in geo.iterrows():\n",
        "    fee_color = colormap(row['fees (EUR)'])\n",
        "\n",
        "    #Selecting an icon based on the fee class\n",
        "    icon = folium.Icon(color='white', icon_color=fee_color, icon='fa-location-dot', prefix='fa')\n",
        "\n",
        "    #Adding a marker to the MarkerCluster with a custom icon\n",
        "    folium.Marker(\n",
        "        location=[row['latitude'], row['longitude']],\n",
        "        icon=icon,\n",
        "        popup=f\"{row['universityName']} - Course: {row['courseName']} - Fees: {int(row['fees (EUR)']):,}\",\n",
        "        tooltip=f\"{row['universityName']} - {row['courseName']} - {float(row['fees (EUR)'])}\"\n",
        "    ).add_to(marker_cluster)\n",
        "\n",
        "#Showing the map\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o6vpUjbi6rt"
      },
      "source": [
        "# 5. Bonus: More complex search engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO9gW76vi6ru"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfQGRUlgi6ru"
      },
      "outputs": [],
      "source": [
        "user_request = json.load(open(\"prova 5.json\")) # read the file where the user specified the requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9AhNHbQi6rv"
      },
      "source": [
        "First filter the dataset with those information the user gave us, such as the fees range, the countries and the presence of online modality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqaWCyYei6rv"
      },
      "outputs": [],
      "source": [
        "dataset = dataset[dataset['fees (EUR)'].notna()]\n",
        "dataset = dataset[dataset['fees (EUR)']!= 'EUR']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ULfw5U_i6rv"
      },
      "outputs": [],
      "source": [
        "dataset = dataset[dataset['country'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_GxOXC4i6rw"
      },
      "outputs": [],
      "source": [
        "# filtering based on the fees range\n",
        "dataset_filtered = dataset[(dataset['fees (EUR)'] >= user_request['Fees Range']['lower import']) &\n",
        "                           (dataset['fees (EUR)'] <= user_request['Fees Range']['upper import'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lK_DwPr6i6rw"
      },
      "outputs": [],
      "source": [
        "# filtering on the country list\n",
        "df_f = []\n",
        "for c in user_request[\"list of countries\"]:\n",
        "    df = dataset_filtered[dataset_filtered['country'] == c ]\n",
        "    df_f.append(df)\n",
        "df_f = pd.concat(df_f, ignore_index = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FiYLpHSi6rw"
      },
      "outputs": [],
      "source": [
        "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "current_month = 11\n",
        "months_to_keep = months[current_month-4:current_month]\n",
        "\n",
        "# Function to check if any of the months of the starting date are present in the start date\n",
        "def filter_months(row):\n",
        "    start_dates = row.split(', ')\n",
        "    return any(month in start_dates for month in months_to_keep)\n",
        "\n",
        "# Applying the filter\n",
        "df_filtered= df_f[df_f['startDate'].apply(filter_months)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQC6LYrai6rx"
      },
      "outputs": [],
      "source": [
        "# filtering on the presence of the online modality\n",
        "df_filtered = df_filtered[df_filtered['administration'] != 'On Campus']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOYoydBHi6rx"
      },
      "source": [
        "Now that we have filtered the courses that respect the fees range, the countries, the start date (and the online modality??) we are going to estimate the similarity score between the queries on the features expresses by th euser and each of the filtered master."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHpRvsXSi6ry",
        "outputId": "81e36383-702f-4995-9c65-c16169e6543a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'courseName': 'Healthcare management and leadership', 'universityName': 'Worcester', 'city': 'Worcester'}\n"
          ]
        }
      ],
      "source": [
        "# checking in the json file all the fields requested by the user to perform the query on\n",
        "query = {}\n",
        "\n",
        "if user_request['query on features']['courseName'] != \"\":\n",
        "    query['courseName'] = user_request['query on features']['courseName']\n",
        "\n",
        "if user_request['query on features']['universityName'] != \"\":\n",
        "    query['universityName'] = user_request['query on features']['universityName']\n",
        "\n",
        "if user_request['query on features']['universityCity'] != \"\":\n",
        "    query['city'] = user_request['query on features']['universityCity']\n",
        "\n",
        "print(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_i6-TOri6ry"
      },
      "source": [
        "Creating the inverted index of all the fields of the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knj49NQ9i6ry"
      },
      "outputs": [],
      "source": [
        "# creating the inverted index of all the fields requested by the user\n",
        "\n",
        "for field in query.keys():\n",
        "    df_filtered = df_filtered.copy()\n",
        "    # performing on that fields the 3 steps of the preprocess\n",
        "    # 1. stemming\n",
        "    name = f'clean_{field}'\n",
        "    df_filtered[name] = df_filtered[field].apply(stem_description)\n",
        "    # 2. removing stopwords\n",
        "    df_filtered[name] = df_filtered[name].apply(remove_stopwords)\n",
        "    # 3. removing punctuation\n",
        "    df_filtered[name] = df_filtered[name].apply(remove_punctuation)\n",
        "\n",
        "    # creating the vocabulary of the fields\n",
        "    vocabulary = Counter(reduce(lambda x,y : x+y, df_filtered[name])).keys()\n",
        "    # assign an unique ID to each word of the vocabulary using a pandas dataframe\n",
        "    terms = pd.DataFrame(data=list(vocabulary), columns=['term'])\n",
        "    # creating a csv file for the vocabulary with index of each term\n",
        "    terms.to_csv(f'vocabulary_{field}.csv', index_label='term_id')\n",
        "\n",
        "    # create the inverse index for each term in each field\n",
        "    terms['reverse'] = terms.term.apply(lambda item: list(df_filtered.loc[df_filtered[name].apply(lambda row: item in row)].index))\n",
        "\n",
        "    # save the inverted index in a file\n",
        "    InvertedIndex = terms['reverse'].to_dict()\n",
        "    # store the inverted index in a txt file\n",
        "    with open(f'Inverted Index {field}.txt', 'w') as file:\n",
        "        for key, value in InvertedIndex.items():\n",
        "            file.write(f'{key}: {value}\\n')\n",
        "    file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5oHkdO3i6rz"
      },
      "source": [
        "Preprocessing the query for each field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMjRf_8ui6rz",
        "outputId": "a0a8bcc5-8909-4425-dec7-a18a3af6e764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'courseName': ['healthcar', 'manag', 'leadership'], 'universityName': ['worcest'], 'city': ['worcest']}\n"
          ]
        }
      ],
      "source": [
        "# preprocess the query\n",
        "preproc_query = {}\n",
        "for field in query.keys():\n",
        "    preproc_query[field] = query_preprocess(query[field])\n",
        "\n",
        "print(preproc_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnt20nyli6r0"
      },
      "source": [
        "Evaluating the *tfidf* scores for each field of the query and creating the extended inverted index for each of the field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWTr6WW0i6r0",
        "outputId": "d207bf82-f44e-4063-fc98-1e8ba3525019"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# if the user specified the course name\n",
        "if query['courseName']:\n",
        "\n",
        "#Convert a collection of raw documents to a matrix of TF-Idataset features\n",
        "\n",
        "    tfidataset = TfidfVectorizer(input='content', lowercase=False, tokenizer=lambda text: text)\n",
        "    results = tfidataset.fit_transform(df_filtered.clean_courseName) # fit data to train our model (but in our case is the same dataset)\n",
        "    results_dense = results.todense() # results are sparse documents that i want to convert into a dense one\n",
        "\n",
        "    # putting all into a dataframe where the index of the dataframe is each document id\n",
        "    tfidataset_data_courseName = pd.DataFrame(results_dense.tolist(), index=df_filtered.index, columns=tfidataset.get_feature_names_out())\n",
        "\n",
        "    vocabulary_courseName = pd.read_csv('vocabulary_courseName.csv') # read the vocabulary file into a dataframe\n",
        "    vocabulary_courseName = pd.DataFrame(vocabulary_courseName)\n",
        "    file = open(\"Inverted Index courseName.txt\", \"r\") # read the inverted index from the file.\n",
        "    inv_indx_courseName = dict()\n",
        "    txt = file.read().split(\"\\n\")\n",
        "\n",
        "    for i in range(len(txt)-1):\n",
        "        line = txt[i].replace(\":\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").split(\" \")\n",
        "        inv_indx_courseName[int(line[0])] = []\n",
        "        for j in range(1, len(line)):\n",
        "                inv_indx_courseName[int(line[0])].append(int(line[j]))\n",
        "    file.close()\n",
        "\n",
        "    # creating the second inverted index\n",
        "    create_second_inverted_index(inv_indx=inv_indx_courseName, vocabulary=vocabulary_courseName, tfidataset_data=tfidataset_data_courseName, feat = 'courseName')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPwWogJRi6r1",
        "outputId": "85e7b03e-8003-43db-ef30-c68cec509f74"
      },
      "outputs": [],
      "source": [
        "# if the user specified the university name\n",
        "\n",
        "if query['universityName']:\n",
        "\n",
        "    #Convert a collection of raw documents to a matrix of TF-Idataset features\n",
        "\n",
        "    tfidataset = TfidfVectorizer(input='content', lowercase=False, tokenizer=lambda text: text)\n",
        "    results = tfidataset.fit_transform(df_filtered.clean_universityName) # fit data to train our model (but in our case is the same dataset)\n",
        "    results_dense = results.todense() # results are sparse documents that i want to convert into a dense one\n",
        "\n",
        "    # putting all into a dataframe where the index of the dataframe is each document id\n",
        "    tfidataset_data_universityName = pd.DataFrame(results_dense.tolist(), index=df_filtered.index, columns=tfidataset.get_feature_names_out())\n",
        "\n",
        "    vocabulary_universityName = pd.read_csv('vocabulary_universityName.csv') # read the vocabulary file into a dataframe\n",
        "    vocabulary_universityName = pd.DataFrame(vocabulary_universityName)\n",
        "    file = open(\"Inverted Index universityName.txt\", \"r\") # read the inverted index from the file.\n",
        "    inv_indx_universityName = dict()\n",
        "    txt = file.read().split(\"\\n\")\n",
        "\n",
        "    for i in range(len(txt)-1):\n",
        "        line = txt[i].replace(\":\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").split(\" \")\n",
        "        inv_indx_universityName[int(line[0])] = []\n",
        "        for j in range(1, len(line)):\n",
        "                inv_indx_universityName[int(line[0])].append(int(line[j]))\n",
        "    file.close()\n",
        "\n",
        "        # creating the second inverted index\n",
        "    create_second_inverted_index(inv_indx= inv_indx_universityName, vocabulary=vocabulary_universityName, tfidataset_data=tfidataset_data_universityName, feat = 'universityName')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BkO-FSmi6r1",
        "outputId": "c2b9fe07-5462-4c2f-ddab-6805f6015cbf"
      },
      "outputs": [],
      "source": [
        "# if the user specified the university city\n",
        "\n",
        "if query['city']:\n",
        "\n",
        "    #Convert a collection of raw documents to a matrix of TF-Idataset features\n",
        "\n",
        "    tfidataset = TfidfVectorizer(input='content', lowercase=False, tokenizer=lambda text: text)\n",
        "    results = tfidataset.fit_transform(df_filtered.clean_city) # fit data to train our model (but in our case is the same dataset)\n",
        "    results_dense = results.todense() # results are sparse documents that i want to convert into a dense one\n",
        "\n",
        "    # putting all into a dataframe where the index of the dataframe is each document id\n",
        "    tfidataset_data_city = pd.DataFrame(results_dense.tolist(), index=df_filtered.index, columns=tfidataset.get_feature_names_out())\n",
        "\n",
        "    vocabulary_city = pd.read_csv('vocabulary_city.csv') # read the vocabulary file into a dataframe\n",
        "    vocabulary_city = pd.DataFrame(vocabulary_city)\n",
        "    file = open(\"Inverted Index city.txt\", \"r\") # read the inverted index from the file.\n",
        "    inv_indx_city = dict()\n",
        "    txt = file.read().split(\"\\n\")\n",
        "\n",
        "    for i in range(len(txt)-1):\n",
        "        line = txt[i].replace(\":\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").split(\" \")\n",
        "        inv_indx_city[int(line[0])] = []\n",
        "        for j in range(1, len(line)):\n",
        "                inv_indx_city[int(line[0])].append(int(line[j]))\n",
        "    file.close()\n",
        "\n",
        "        # creating the second inverted index\n",
        "    create_second_inverted_index( inv_indx= inv_indx_city, vocabulary= vocabulary_city, tfidataset_data=tfidataset_data_city, feat = 'city')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH_PSTWoi6r2"
      },
      "outputs": [],
      "source": [
        "# read the inverted index from the file for the course name, if any\n",
        "\n",
        "if query['courseName']:\n",
        "    ext_inv_indx_courseName = read_inverted_index('courseName')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS_tT466i6r3"
      },
      "outputs": [],
      "source": [
        "# read the inverted index from the file for the university name, if any\n",
        "\n",
        "if query['universityName']:\n",
        "    ext_inv_indx_universityName = read_inverted_index('universityName')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoChViGPi6r3"
      },
      "outputs": [],
      "source": [
        "# read the inverted index from the file for the city name, if any\n",
        "\n",
        "if query['city']:\n",
        "    ext_inv_indx_city = read_inverted_index('city')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_JPS6hvi6r3"
      },
      "source": [
        "Now we execute the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVsfDwzei6r4"
      },
      "outputs": [],
      "source": [
        "# create a vector for the query\n",
        "# one vector for each part of the query\n",
        "\n",
        "if query['courseName']:\n",
        "    query_vec_courseName = create_vector_query(query = preproc_query['courseName'], vocabulary = vocabulary_courseName, tfidataset_data= tfidataset_data_courseName)\n",
        "\n",
        "\n",
        "if query['universityName']:\n",
        "    query_vec_univerityName = create_vector_query(query = preproc_query['universityName'], vocabulary = vocabulary_universityName, tfidataset_data= tfidataset_data_universityName)\n",
        "\n",
        "\n",
        "if query['city']:\n",
        "    query_vec_city = create_vector_query(query = preproc_query['city'], vocabulary = vocabulary_city, tfidataset_data= tfidataset_data_city)\n",
        "\n",
        "# the documents matrix with all the tfidataset is the dataframe tfidataset of the field"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slmx0hEni6r4"
      },
      "source": [
        "Now we evaluate the similarity for each field of the query, obtaining as a result up to 3 dataframes (depending on the fields the user specified for the query); each resulting dataframe will contain the masters that are more similar to the query according the cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-82d6Hdi6r4",
        "outputId": "87996105-71c9-41e7-dd0e-771433112016"
      },
      "outputs": [],
      "source": [
        "k = 5\n",
        "if query['courseName']:\n",
        "    heap_courseName = []\n",
        "    scores_dictionary_courseName = {}\n",
        "\n",
        "    # For every document\n",
        "    for doc_index in range(1, tfidataset_data_courseName.shape[0]):\n",
        "        if doc_index in tfidataset_data_courseName.index:\n",
        "            doc_arr = tfidataset_data_courseName.loc[doc_index, :].values\n",
        "            # Compute the angle between the doc and the query vector\n",
        "            cos_sim = a_cosine_similarity(query_vec_courseName, doc_arr)\n",
        "\n",
        "            # Put the result in the dictionary\n",
        "            scores_dictionary_courseName[doc_index] = cos_sim\n",
        "\n",
        "            # Update the heap\n",
        "            heapq.heappush(heap_courseName, (cos_sim, doc_index))  # Store both score and document index in the heap\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    # execute the query\n",
        "    top_k_courseName = heapq.nlargest(k, heap_courseName)\n",
        "\n",
        "    top_doc_k_courseName= []\n",
        "\n",
        "    # fill the list of top_k_doc\n",
        "    for score, doc in top_k_courseName:\n",
        "        top_doc_k_courseName.append(doc)\n",
        "\n",
        "    # adding the column 'similarity score' to the dataset\n",
        "    information_needed = ['courseName','universityName','description','city', 'url']\n",
        "    results_courseName = df_filtered.loc[top_doc_k_courseName , information_needed]\n",
        "    results_courseName['similarity'] = [round(s[0],3) for s in top_k_courseName]\n",
        "\n",
        "\n",
        "if query['universityName']:\n",
        "    heap_universityName = []\n",
        "    scores_dictionary_universityName = {}\n",
        "\n",
        "    # For every document\n",
        "    for doc_index in range(1, tfidataset_data_universityName.shape[0]):\n",
        "        if doc_index in tfidataset_data_universityName.index:\n",
        "            doc_arr = tfidataset_data_universityName.loc[doc_index, :].values\n",
        "            # Compute the angle between the doc and the query vector\n",
        "            cos_sim = a_cosine_similarity(query_vec_univerityName, doc_arr)\n",
        "\n",
        "            # Put the result in the dictionary\n",
        "            scores_dictionary_universityName[doc_index] = cos_sim\n",
        "\n",
        "            # Update the heap\n",
        "            heapq.heappush(heap_universityName, (cos_sim, doc_index))  # Store both score and document index in the heap\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    # execute the query\n",
        "    top_k_universitName = heapq.nlargest(k, heap_universityName)\n",
        "\n",
        "    top_doc_k_universityName= []\n",
        "\n",
        "    # fill the list of top_k_doc\n",
        "    for score, doc in top_k_universitName:\n",
        "        top_doc_k_universityName.append(doc)\n",
        "\n",
        "    # adding the column 'similarity score' to the dataset\n",
        "    information_needed = ['courseName','universityName','description','city', 'url']\n",
        "    results_universityName = df_filtered.loc[top_doc_k_universityName , information_needed]\n",
        "    results_universityName['similarity'] = [round(s[0],3) for s in top_k_universitName]\n",
        "\n",
        "\n",
        "if query['city']:\n",
        "    heap_city = []\n",
        "    scores_dictionary_city = {}\n",
        "\n",
        "    # For every document\n",
        "    for doc_index in range(1, tfidataset_data_city.shape[0]):\n",
        "        if doc_index in tfidataset_data_city.index:\n",
        "            doc_arr = tfidataset_data_city.loc[doc_index, :].values\n",
        "            # Compute the angle between the doc and the query vector\n",
        "            cos_sim = a_cosine_similarity(query_vec_city, doc_arr)\n",
        "\n",
        "            # Put the result in the dictionary\n",
        "            scores_dictionary_city[doc_index] = cos_sim\n",
        "\n",
        "            # Update the heap\n",
        "            heapq.heappush(heap_city, (cos_sim, doc_index))  # Store both score and document index in the heap\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    # execute the query\n",
        "    top_k_city = heapq.nlargest(k, heap_city)\n",
        "\n",
        "    top_doc_k_city= []\n",
        "\n",
        "    # fill the list of top_k_doc\n",
        "    for score, doc in top_k_city:\n",
        "        top_doc_k_city.append(doc)\n",
        "\n",
        "    # adding the column 'similarity score' to the dataset\n",
        "    information_needed = ['courseName','universityName','description','city', 'url']\n",
        "    results_city = df_filtered.loc[top_doc_k_city , information_needed]\n",
        "    results_city['similarity'] = [round(s[0],3) for s in top_k_city]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWplpv4di6r5",
        "outputId": "5bf5d536-d421-42e0-e2a2-f30734450496"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>courseName</th>\n",
              "      <th>universityName</th>\n",
              "      <th>description</th>\n",
              "      <th>city</th>\n",
              "      <th>url</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>MSc Nursing</td>\n",
              "      <td>University of Essex Online</td>\n",
              "      <td>Start Date: SeptemberThe demand for skilled nu...</td>\n",
              "      <td>Colchester</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>MSc Data Science</td>\n",
              "      <td>University of Essex Online</td>\n",
              "      <td>Start Date: OctoberUse the power of data to ma...</td>\n",
              "      <td>Colchester</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>MSc Organisational Psychology</td>\n",
              "      <td>University of Essex Online</td>\n",
              "      <td>Start Date: OctoberMSc Organisational Psycholo...</td>\n",
              "      <td>Colchester</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>MSc International Human Resource Management</td>\n",
              "      <td>University of Essex Online</td>\n",
              "      <td>Start Date: OctoberIn a world with an increasi...</td>\n",
              "      <td>Colchester</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>MSc International Healthcare Management</td>\n",
              "      <td>University of Essex Online</td>\n",
              "      <td>Start Date: SeptemberHealthcare is a subject a...</td>\n",
              "      <td>Colchester</td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     courseName              universityName  \\\n",
              "17                                  MSc Nursing  University of Essex Online   \n",
              "10                             MSc Data Science  University of Essex Online   \n",
              "19                MSc Organisational Psychology  University of Essex Online   \n",
              "16  MSc International Human Resource Management  University of Essex Online   \n",
              "15      MSc International Healthcare Management  University of Essex Online   \n",
              "\n",
              "                                          description        city  \\\n",
              "17  Start Date: SeptemberThe demand for skilled nu...  Colchester   \n",
              "10  Start Date: OctoberUse the power of data to ma...  Colchester   \n",
              "19  Start Date: OctoberMSc Organisational Psycholo...  Colchester   \n",
              "16  Start Date: OctoberIn a world with an increasi...  Colchester   \n",
              "15  Start Date: SeptemberHealthcare is a subject a...  Colchester   \n",
              "\n",
              "                                                  url  similarity  \n",
              "17  https://www.findamasters.com/masters-degrees/c...       0.675  \n",
              "10  https://www.findamasters.com/masters-degrees/c...       0.517  \n",
              "19  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "16  https://www.findamasters.com/masters-degrees/c...       0.000  \n",
              "15  https://www.findamasters.com/masters-degrees/c...       0.000  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_courseName"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwHu4kh4i6r6"
      },
      "source": [
        "Finally we have to aggregate our results unifying the datasets and summing the similarity score of each master if it appears in more than one result.\\\n",
        "The result of the query will be only those masters that have a similarity grater than 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A-BM9t1i6r6",
        "outputId": "d6273726-8634-44c9-8df0-56ee81c8968e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>courseName</th>\n",
              "      <th>universityName</th>\n",
              "      <th>facultyName</th>\n",
              "      <th>isItFullTime</th>\n",
              "      <th>description</th>\n",
              "      <th>startDate</th>\n",
              "      <th>modality</th>\n",
              "      <th>duration</th>\n",
              "      <th>fees (EUR)</th>\n",
              "      <th>country</th>\n",
              "      <th>city</th>\n",
              "      <th>administration</th>\n",
              "      <th>url</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>MSc Data Science</td>\n",
              "      <td>University of Essex Online</td>\n",
              "      <td>Online Masters Degree Programmes</td>\n",
              "      <td>Part Time</td>\n",
              "      <td>Start Date: OctoberUse the power of data to ma...</td>\n",
              "      <td>October, January</td>\n",
              "      <td>MSc</td>\n",
              "      <td>2 Years Part Time</td>\n",
              "      <td>13580.402731</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Colchester</td>\n",
              "      <td></td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>MSc Nursing</td>\n",
              "      <td>University of Essex Online</td>\n",
              "      <td>Online Masters Degree Programmes</td>\n",
              "      <td>Part Time</td>\n",
              "      <td>Start Date: SeptemberThe demand for skilled nu...</td>\n",
              "      <td>September, January</td>\n",
              "      <td>MSc</td>\n",
              "      <td>2 years</td>\n",
              "      <td>13580.402731</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Colchester</td>\n",
              "      <td></td>\n",
              "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
              "      <td>0.675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          courseName              universityName  \\\n",
              "10  MSc Data Science  University of Essex Online   \n",
              "17       MSc Nursing  University of Essex Online   \n",
              "\n",
              "                         facultyName isItFullTime  \\\n",
              "10  Online Masters Degree Programmes    Part Time   \n",
              "17  Online Masters Degree Programmes    Part Time   \n",
              "\n",
              "                                          description           startDate  \\\n",
              "10  Start Date: OctoberUse the power of data to ma...    October, January   \n",
              "17  Start Date: SeptemberThe demand for skilled nu...  September, January   \n",
              "\n",
              "   modality           duration    fees (EUR)         country        city  \\\n",
              "10      MSc  2 Years Part Time  13580.402731  United Kingdom  Colchester   \n",
              "17      MSc            2 years  13580.402731  United Kingdom  Colchester   \n",
              "\n",
              "   administration                                                url  \\\n",
              "10                 https://www.findamasters.com/masters-degrees/c...   \n",
              "17                 https://www.findamasters.com/masters-degrees/c...   \n",
              "\n",
              "    similarity  \n",
              "10       0.517  \n",
              "17       0.675  "
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sum of the scores\n",
        "\n",
        "grouped_res = pd.concat([results_courseName, results_universityName, results_city])\n",
        "result = grouped_res.groupby(grouped_res.index).agg({'similarity':'sum'})\n",
        "result = result[result.similarity > 0.0]\n",
        "a = result.to_dict() # the dictionary of the indexes of those masters that have summed similarity > 0.0\n",
        "\n",
        "df_filtered['similarity'] = 0.0  # Initialize a new column with None\n",
        "\n",
        "for ind in a['similarity'].keys():\n",
        "    df_filtered.loc[ind,'similarity'] = a['similarity'][ind]\n",
        "\n",
        "result = df_filtered.drop(['descr_stem','description_clean', 'clean_courseName', 'clean_universityName', 'clean_city'], axis = 1)\n",
        "result = result[result['similarity']>0.0]\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1mquF_oi6r7"
      },
      "source": [
        "# 6. Command Line Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_U5kqFFi6r7"
      },
      "source": [
        "In the Command Line script, instructions have been included for creating the merged_courses file and for responding to the proposed questions. The results obtained align with our expectations. Look at the CommandLine.sh file in the github repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eStpOmK3i6r7"
      },
      "source": [
        "# 7. Algorithmic Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbcMDHfZi6r7",
        "outputId": "247e06cf-5296-4eef-805d-53e9673cb13c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 5\n",
            "0 1\n",
            "3 5\n",
            "YES\n",
            "1 4\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# Read D and x from the console\n",
        "D, x = map(int, input().split())\n",
        "\n",
        "# Initialize the sums of minis and maxis\n",
        "sum_mini = 0\n",
        "sum_maxi = 0\n",
        "\n",
        "minis = []\n",
        "maxis = []\n",
        "\n",
        "# Read the intervals and calculate the sums\n",
        "for _ in range(D):\n",
        "    mini, maxi = map(int, input().split())\n",
        "    sum_mini += mini\n",
        "    sum_maxi += maxi\n",
        "    minis.append(mini)\n",
        "    maxis.append(maxi)\n",
        "\n",
        "# Check if x belongs to the [sum of minis, sum of maxis] interval and if x matches the sum of minis or maxis\n",
        "if sum_mini <= x <= sum_maxi:\n",
        "    if x == sum_mini:\n",
        "        if any(val == 0 for val in minis):\n",
        "            print(\"NO\")\n",
        "            sys.exit(0)\n",
        "        print(\"YES\")\n",
        "        print(\" \".join(map(str, minis)))\n",
        "        sys.exit(0)\n",
        "    elif x == sum_maxi:\n",
        "        if any(val == 0 for val in maxis):\n",
        "            print(\"NO\")\n",
        "            sys.exit(0)\n",
        "        print(\"YES\")\n",
        "        print(\" \".join(map(str, maxis)))\n",
        "        sys.exit(0)\n",
        "    print(\"YES\")\n",
        "else:\n",
        "    print(\"NO\")\n",
        "    sys.exit(0)\n",
        "\n",
        "# Use for loops to generate tuples\n",
        "# The tuples variable will contain all the D-tuples\n",
        "tuples = [()]\n",
        "\n",
        "for i in range(D):\n",
        "    new_tuples = []\n",
        "    for tuple_str in tuples:\n",
        "        for val in range(minis[i], maxis[i] + 1):\n",
        "            new_tuples.append(tuple_str + (val,))\n",
        "    tuples = new_tuples\n",
        "\n",
        "# Print the generated tuples\n",
        "for tuple_str in tuples:\n",
        "    exclude_tuple = any(val == 0 for val in tuple_str)\n",
        "\n",
        "    if not exclude_tuple:\n",
        "        current_sum = sum(tuple_str)\n",
        "\n",
        "        if x == current_sum:\n",
        "            print(\" \".join(map(str, tuple_str)).lstrip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvlHD-DRmQsM"
      },
      "source": [
        "In the previous code, all tuples containing one or more zeros have been excluded because the report needs to indicate the hours worked for each day and we assumed that 0 was not an acceptable answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX3PS9Iri6r8"
      },
      "source": [
        "We analyze the time complexity of this script:\n",
        "\n",
        "*   *Reading intervals*: Requires O(D) operations;\n",
        "*   *Tuple generation*: For each interval, a for loop is executed with up to (maxi - mini + 1) iterations. This loop is repeated for each interval, so the total complexity of this part is O((maxi - mini + 1)^D). If we consider that (maxi - mini) is somehow bounded by a constant, we can approximate this complexity to O(M^D), where M represents the maximum range among all intervals.;\n",
        "*   *Filtering tuples containing 0, calculating the sum, and comparing with x*: This requires O(M^D) operations in the worst case.\n",
        "\n",
        "Therefore, the total complexity is O(M^D). This complexity can become prohibitive for high values of D, but it can be manageable if the number of intervals and the width of the intervals are relatively small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OAPen01i6r8"
      },
      "source": [
        "ChatGPT analysis:\n",
        "\n",
        "The time complexity of the provided code depends mainly on the part where tuples are generated, as that is the most costly operation.\n",
        "\n",
        "The tuple generation part has a time complexity of O((maxis[0] - minis[0] + 1) * (maxis[1] - minis[1] + 1) * ... * (maxis[D-1] - minis[D-1] + 1)), where D is the number of iterations (number of tuples). Therefore, the time complexity of this part of the code is exponential with respect to D.\n",
        "\n",
        "The rest of the code, in terms of sums and comparisons, has a linear time complexity in relation to D.\n",
        "\n",
        "Thus, the overall time complexity of the code is dominated by the tuple generation and can be approximated as O((maxis[0] - minis[0] + 1) * (maxis[1] - minis[1] + 1) * ... * (maxis[D-1] - minis[D-1] + 1)).\n",
        "\n",
        "This exponential complexity might make the program inefficient for significantly large values of D.\n",
        "\n",
        "\n",
        "\n",
        "So, the two analyses arrive at the same conclusions but with different notations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osiQ57kIi6r9"
      },
      "source": [
        "We submitted the previous code to ChatGPT to improve its efficiency, and it suggests replacing the for loops with itertools.product to generate all tuples more efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqxpUxZri6r9"
      },
      "source": [
        "Optimized Code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s75zAaVTi6r9",
        "outputId": "305b46de-9087-4e66-825e-9f475a881ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 5\n",
            "0 1\n",
            "3 5\n",
            "YES\n",
            "1 4\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from itertools import product\n",
        "\n",
        "# Read D and x from the console\n",
        "D, x = map(int, input().split())\n",
        "\n",
        "# Initialize the sums of minis and maxis\n",
        "sum_mini = 0\n",
        "sum_maxi = 0\n",
        "\n",
        "minis = []\n",
        "maxis = []\n",
        "\n",
        "# Read the intervals and calculate the sums\n",
        "for _ in range(D):\n",
        "    mini, maxi = map(int, input().split())\n",
        "    sum_mini += mini\n",
        "    sum_maxi += maxi\n",
        "    minis.append(mini)\n",
        "    maxis.append(maxi)\n",
        "\n",
        "# Check if x belongs to the [sum of minis, sum of maxis] interval and if x matches the sum of minis or maxis\n",
        "if sum_mini <= x <= sum_maxi:\n",
        "    if x == sum_mini:\n",
        "        if any(val == 0 for val in minis):\n",
        "            print(\"NO\")\n",
        "            sys.exit(0)\n",
        "        print(\"YES\")\n",
        "        print(\" \".join(map(str, minis)))\n",
        "        sys.exit(0)\n",
        "    elif x == sum_maxi:\n",
        "        if any(val == 0 for val in maxis):\n",
        "            print(\"NO\")\n",
        "            sys.exit(0)\n",
        "        print(\"YES\")\n",
        "        print(\" \".join(map(str, maxis)))\n",
        "        sys.exit(0)\n",
        "    print(\"YES\")\n",
        "else:\n",
        "    print(\"NO\")\n",
        "    sys.exit(0)\n",
        "\n",
        "# Use itertools.product to generate tuples\n",
        "tuples = product(*(range(mini, maxi + 1) for mini, maxi in zip(minis, maxis)))\n",
        "\n",
        "# Print the generated tuples\n",
        "for tuple_str in tuples:\n",
        "    exclude_tuple = any(val == 0 for val in tuple_str)\n",
        "\n",
        "    if not exclude_tuple:\n",
        "        current_sum = sum(tuple_str)\n",
        "\n",
        "        if x == current_sum:\n",
        "            print(\" \".join(map(str, tuple_str)).lstrip())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
